## Background

<!--
    Why would we need to randomize networks?
    * How can we contextualize this approach? Like "Monte Carlo"? Or more like a permutation test?
-->

<!--
    Why should degree be preserved?
    * Need to show that degree is a massive confounder
    * Citations would be helpful here, but maybe scant empirical proof
        * How do you even prove something is a "confounder"?
-->

<!-- Other methods to get similar results? Chung-Lu, "configuration model"? etc. -->

<!--
    XSwap algorithm
    * Background -> Original paper
-->

## Methods

<!--
    XSwap algorithm
    * Modifications we made to the original method... if any?
    * Pseudocode
-->

<!--
    Implementation (fairly brief)
    * Why Python
    * Why C++
    * Brief architecture discussion
-->

<!--
    Comparisons
    * XSwap-randomization vs other kinds of background performance metrics
    * Other graphs
    * Other predictive tasks/implementations
-->

## Results

<!-- Performance of XSwap itself -->
<!-- x: Number of attempts, y: Number of successful swaps -->
<!-- x: Number of attempts, y: Percent of edges unchanged -->
<!-- Network density vs (fractional) attempts to 50% (or some cutoff) changed -->
<!-- Is it possible to estimate the fraction of the random graph space that is being explored by XSwap? -->
<!-- Is there a closed-form solution for the probability of an edge after a certain number of swaps? -->

<!-- Comparisons of other methods through the use of XSwap -->

## Discussion

