## Acknowledgments

The authors thank [Blair Sullivan](https://orcid.org/0000-0001-7720-6208) for [her feedback](https://github.com/greenelab/xswap-manuscript/issues/54) on a draft of the manuscript.

## References {.page_break_before}

<!-- Explicitly insert bibliography here -->
<div id="refs"></div>

## Supplemental information

### XSwap parameter settings for network types

| Network type | Degree preserved | Figure | `allow_antiparallel` | `allow_loops` |
| :----------- | :--------------- | :----- | :------------------- | :----------------- |
| simple | all | ![](images/xswap_simple.png){height="85px"} | False | False |
| directed | in/out | ![](images/xswap_directed.png){height="85px"} | Depends on networks | Depends on networks |
| bipartite | Depends on directedness | ![](images/xswap_bipartite.png){height="85px"} | True | True |

Table:
Applications of the modified XSwap algorithm to various network types with appropriate parameter choices.
For simple networks, each node's degree is preserved.
For bipartite networks, each node's number of connections to the other part is preserved, and the partite sets (node class memberships) are preserved.
For directed networks, each nodes' in- and out-degrees are preserved, though parameter choices depend on the network being permuted.
Some directed networks can include antiparallel edges or loops while others do not. {#tbl:xswap}

### Performance of the XSwap algorithm

The performance of the XSwap algorithm depends on a number of network properties.
We define network density to be the number of edges divided by the number of potential edges.
Increasing network density lowers the asymptotic fraction of edges changed, as greater density prevents the algorithm from removing certain edges.
Random graphs generated with a preferential attachment mechanism (via Barabási–Albert) can have a lower fraction of their edges swapped, asymptotically, as compared to uniform random graphs (via Erdős–Rényi).

![Higher density networks have lower asymptotic fractions of edges swapped and take more attempts to reach these values.
  The Barabási–Albert model produces scale-free random graphs, while Erdős–Rényi generates random graphs where all edges are equally likely.
  ](https://github.com/greenelab/xswap-analysis/raw/47f67f85b1a5df2714d564c274515f1fdeb882ba/img/6_xswap_percent_swapped_iterations/lines_continuous.png){#fig:swap-percent width="100%"}

### Approximate edge prior {#approx-prior-supp}

To approximate the edge prior, we began by making two simplifications.
First, we assumed independence between node pairs.
This assumption does not actually hold for the XSwap algorithm, though it is a reasonable simplification for large, sparse networks.
Second, we assumed that the XSwap process is stationary.
This assumption also does not actually hold, but it was made because it significantly simplifies the problem.
A single node pair has two possible states, "edge" and "no edge".
These states are not transient, and they are not periodic so long as more than one possible swap exists in the network.
In almost all cases, then, our simplified model of the algorithm gives the state of a node pair as an ergodic process, independent of other node pairs.

Let $A_{i,j}$ represent the existence of edge $(i, j)$
For a given node pair, $(i, j)$, then, let $q_{i,j}$ represent the transition probability from the "no edge" state to the "edge" state in one successful iteration of the XSwap algorithm.
Let $r_{i,j}$ represent the probability of the opposite transition ("edge" to "no edge") in one successful iteration.
With "no edge" represented as $[1, 0]^T$ and "edge" represented as $[0, 1]^T$, the transition matrix, $P$, is given by the following:

\begin{align*}
    P^T &= \begin{bmatrix}
       1-q & r \\
       q & 1-r
     \end{bmatrix}
\end{align*}

The stationary distribution of this system should correspond to the distribution when the number of swaps goes to infinity.
It can be found by computing the eigenvectors of the system, as we know that the stationary distribution vector, $\mathbf{v}$ satisfies $P^T \mathbf{v} = \mathbf{v}$.
The eigenvector $\mathbf{v}$, normalized to sum to 1 as a probability vector, is given by

\begin{align*}
    \mathbf{v} = \frac{1}{r + q} \begin{bmatrix}
        r \\
        q
    \end{bmatrix}
\end{align*}

The asymptotic edge probability is therefore

$$\frac{q}{r + q}.$$

Since node pairs are being treated as independent, the probability of an edge being created in one successful iteration, given that the edge does not currently exist, is the ratio of the number of edge choices involving nodes $i$ and $j$ to the total number of possible swaps, $S$.
Let $d(u_i)$ represent the degree of source node $i$ and $d(v_j)$ represent the degree of target node $j$.

$$q_{i,j} = \frac{d(u_i)d(v_j)}{S}$$

Similarly, the probability of an edge being eliminated in one iteration is the ratio of the number of edge choices involving $(i,j)$ and any other valid edge to the total number of possible swaps.
Let $m$ be the total number of edges in the network.

$$r_{i,j} = \frac{m - d(u_i) - d(v_j) + 1}{S}$$

The approximate edge prior is, therefore,

$$\frac{d(u_i)d(v_j)}{m - d(u_i) - d(v_j) + 1 + d(u_i)d(v_j)}.$$

Unfortunately, we found that the above edge prior approximation is a poor approximation in many cases.
We found that the following modified form (introduced in Methods) affords a superior approximation:

\begin{equation}
    P_{i,j} = \frac{d(u_i) d(v_j)}{\sqrt{(d(u_i) d(v_j))^2 + (m - d(u_i) - d(v_j) + 1)^2}}
\end{equation}

Interestingly, this expression can be derived by normalizing the eigenvector $\mathbf{v}$ to be a unit vector in the 2-norm instead of the 1-norm; that is, we use the value $q / \sqrt{r^2 + q^2}$ instead of $q/(r+q)$.
Because the modified form of the approximation offers a much superior fit to the data, we chose to include only the modified version in the released Python package, and we used the modified form throughout our analysis.

### Networks used for comparison {#networks}

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border-width:1px;border-style:solid;border-color:#ccc;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}
.tg .tg-buh4{background-color:#f9f9f9;text-align:left;vertical-align:top}
.tg .tg-mrzz{background-color:#f9f9f9;text-align:left}
.tg .tg-s268{text-align:left}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style>
<table class="tg">
  <tr>
    <th class="tg-s268">Data</th>
    <th class="tg-s268">Network</th>
    <th class="tg-s268">Nodes</th>
    <th class="tg-0lax">Edges</th>
  </tr>
  <tr>
    <td class="tg-s268" rowspan="20">Hetionet</td>
    <td class="tg-mrzz">AdG</td>
    <td class="tg-mrzz">Source: 402, Target: 20945</td>
    <td class="tg-buh4">102240</td>
  </tr>
  <tr>
    <td class="tg-s268">AeG</td>
    <td class="tg-s268">Source: 402, Target: 20945</td>
    <td class="tg-0lax">526407</td>
  </tr>
  <tr>
    <td class="tg-mrzz">AlD</td>
    <td class="tg-mrzz">Source: 402, Target: 137</td>
    <td class="tg-buh4">3602</td>
  </tr>
  <tr>
    <td class="tg-s268">AuG</td>
    <td class="tg-s268">Source: 402, Target: 20945</td>
    <td class="tg-0lax">97848</td>
  </tr>
  <tr>
    <td class="tg-mrzz">BPpG</td>
    <td class="tg-mrzz">Source: 11381, Target: 20945</td>
    <td class="tg-buh4">559504</td>
  </tr>
  <tr>
    <td class="tg-s268">CCpG</td>
    <td class="tg-s268">Source: 1391, Target: 20945</td>
    <td class="tg-0lax">73566</td>
  </tr>
  <tr>
    <td class="tg-mrzz">CbG</td>
    <td class="tg-mrzz">Source: 1552, Target: 20945</td>
    <td class="tg-buh4">11571</td>
  </tr>
  <tr>
    <td class="tg-s268">CcSE</td>
    <td class="tg-s268">Source: 1552, Target: 5734</td>
    <td class="tg-0lax">138944</td>
  </tr>
  <tr>
    <td class="tg-mrzz">CdG</td>
    <td class="tg-mrzz">Source: 1552, Target: 20945</td>
    <td class="tg-buh4">21102</td>
  </tr>
  <tr>
    <td class="tg-s268">CrC</td>
    <td class="tg-s268">1552</td>
    <td class="tg-0lax">6486</td>
  </tr>
  <tr>
    <td class="tg-mrzz">CuG</td>
    <td class="tg-mrzz">Source: 1552, Target: 20945</td>
    <td class="tg-buh4">18756</td>
  </tr>
  <tr>
    <td class="tg-s268">DaG</td>
    <td class="tg-s268">Source: 137, Target: 20945</td>
    <td class="tg-0lax">12623</td>
  </tr>
  <tr>
    <td class="tg-mrzz">DdG</td>
    <td class="tg-mrzz">Source: 137, Target: 20945</td>
    <td class="tg-buh4">7623</td>
  </tr>
  <tr>
    <td class="tg-s268">DpS</td>
    <td class="tg-s268">Source: 137, Target: 438</td>
    <td class="tg-0lax">3357</td>
  </tr>
  <tr>
    <td class="tg-mrzz">DuG</td>
    <td class="tg-mrzz">Source: 137, Target: 20945</td>
    <td class="tg-buh4">7731</td>
  </tr>
  <tr>
    <td class="tg-s268">GuG</td>
    <td class="tg-s268">20945</td>
    <td class="tg-0lax">265672</td>
  </tr>
  <tr>
    <td class="tg-mrzz">GcG</td>
    <td class="tg-mrzz">20945</td>
    <td class="tg-buh4">61690</td>
  </tr>
  <tr>
    <td class="tg-s268">GiG</td>
    <td class="tg-s268">20945</td>
    <td class="tg-0lax">147164</td>
  </tr>
  <tr>
    <td class="tg-mrzz">GpMF</td>
    <td class="tg-mrzz">Source: 20945, Target: 2884</td>
    <td class="tg-buh4">97222</td>
  </tr>
  <tr>
    <td class="tg-s268">GpPW</td>
    <td class="tg-s268">Source: 20945, Target: 1822</td>
    <td class="tg-0lax">84372</td>
  </tr>
  <tr>
    <td class="tg-mrzz" rowspan="3">PPI</td>
    <td class="tg-mrzz">Sampled</td>
    <td class="tg-mrzz">3992</td>
    <td class="tg-buh4">255522</td>
  </tr>
  <tr>
    <td class="tg-s268">Literature</td>
    <td class="tg-s268">3992</td>
    <td class="tg-0lax">364743</td>
  </tr>
  <tr>
    <td class="tg-mrzz">Systematic</td>
    <td class="tg-mrzz">3916</td>
    <td class="tg-buh4">12913</td>
  </tr>
  <tr>
    <td class="tg-s268" rowspan="3">bioRxiv</td>
    <td class="tg-s268">Sampled</td>
    <td class="tg-s268">4587</td>
    <td class="tg-0lax">30686</td>
  </tr>
  <tr>
    <td class="tg-mrzz">&lt;2018</td>
    <td class="tg-mrzz">4615</td>
    <td class="tg-buh4">43691</td>
  </tr>
  <tr>
    <td class="tg-s268">All time</td>
    <td class="tg-s268">4615</td>
    <td class="tg-0lax">44963</td>
  </tr>
  <tr>
    <td class="tg-buh4" rowspan="3">TF-TG</td>
    <td class="tg-mrzz">Sampled</td>
    <td class="tg-mrzz">Source: 142, Target: 1396</td>
    <td class="tg-buh4">2689</td>
  </tr>
  <tr>
    <td class="tg-s268">Literature</td>
    <td class="tg-s268">Source: 144, Target: 1406</td>
    <td class="tg-0lax">3496</td>
  </tr>
  <tr>
    <td class="tg-mrzz">Systematic</td>
    <td class="tg-mrzz">Source: 144, Target: 1417</td>
    <td class="tg-buh4">29177</td>
  </tr>
</table>

### Edge prediction features

In the table that follows, let $k(u)$ denote the set of neighbors of node $u$.
Let $\mathbf{A}$ represent the normalized Laplacian adjacency matrix, and let $y_u$ be a vector with all ones except for a one in the $u$-th position.
$x$
For a directed graph, let $A(u)$ denote the set of nodes that node $u$ points to and $D(u)$ the set of nodes that point to $u$.
All definitions that follow are the score between nodes $u$ and $v$.

| Feature | Definition | Citation |
|--------------------------------|----------------------------|-------|
| Jaccard index | $\frac{|k(u) \cap k(v)|}{|k(u) \cup k(v)|}$ | [@doi:10.1002/asi.20591] |
| Preferential attachment score | $|k(u)||k(v)|$ | [@doi:10.1002/asi.20591] |
| Resource allocation index | $\sum_{w \in k(u) \cap k(v)} \frac{1}{|k(w)|}$ | [@doi:10.1140/epjb/e2009-00335-8] |
| Adamic/Adar index | $\sum_{w \in k(u) \cap k(v)} \frac{1}{log|k(w)|}$ | [@doi:10/br5zd3] |
| Random walk with restart score | $c \bigg[ \bigg( \mathbb{I} - (1-c) \mathbf{A}\bigg)^{-1} \mathbf{y}_u \bigg]_v$ | [@doi:10.1145/1014052.1014135;@raw:laplacian] |
| Inference score | $\frac{|A(u) \cap D(v)|}{|A(u)|} + \frac{|D(u) \cap D(v)|}{|D(u)|}$ | [@raw:inference] |

Table: Edge prediction features. {#tbl:edge-prediction}
