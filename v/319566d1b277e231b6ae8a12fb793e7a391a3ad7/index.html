<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Michael Zietz" />
  <meta name="author" content="Daniel S. Himmelstein" />
  <meta name="author" content="Kyle Kloster" />
  <meta name="author" content="Christopher Williams" />
  <meta name="author" content="Michael W. Nagle" />
  <meta name="author" content="Casey S. Greene" />
  <meta name="dcterms.date" content="2022-11-12" />
  <meta name="keywords" content="xswap, permutation, network, hetnets, degree, bioinformatics, python, manubot" />
  <title>The probability of edge existence due to node degree: a baseline for network-based predictions</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/main/manubot/process/header-includes-template.html
  -->
  <meta name="dc.format" content="text/html" />
  <meta property="og:type" content="article" />
  <meta name="dc.title" content="The probability of edge existence due to node degree: a baseline for network-based predictions" />
  <meta name="citation_title" content="The probability of edge existence due to node degree: a baseline for network-based predictions" />
  <meta property="og:title" content="The probability of edge existence due to node degree: a baseline for network-based predictions" />
  <meta property="twitter:title" content="The probability of edge existence due to node degree: a baseline for network-based predictions" />
  <meta name="dc.date" content="2022-11-12" />
  <meta name="citation_publication_date" content="2022-11-12" />
  <meta property="article:published_time" content="2022-11-12" />
  <meta name="dc.modified" content="2022-11-12T20:00:15+00:00" />
  <meta property="article:modified_time" content="2022-11-12T20:00:15+00:00" />
  <meta name="dc.language" content="en-US" />
  <meta name="citation_language" content="en-US" />
  <meta name="dc.relation.ispartof" content="Manubot" />
  <meta name="dc.publisher" content="Manubot" />
  <meta name="citation_journal_title" content="Manubot" />
  <meta name="citation_technical_report_institution" content="Manubot" />
  <meta name="citation_author" content="Michael Zietz" />
  <meta name="citation_author_institution" content="Department of Physics &amp; Astronomy, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America" />
  <meta name="citation_author_orcid" content="0000-0003-0539-630X" />
  <meta name="twitter:creator" content="@ZietzMichael" />
  <meta name="citation_author" content="Daniel S. Himmelstein" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America" />
  <meta name="citation_author_orcid" content="0000-0002-3012-7446" />
  <meta name="twitter:creator" content="@dhimmel" />
  <meta name="citation_author" content="Kyle Kloster" />
  <meta name="citation_author_institution" content="Department of Computer Science, North Carolina State University, Raleigh, North Carolina, United States of America" />
  <meta name="citation_author_orcid" content="0000-0001-5678-7197" />
  <meta name="twitter:creator" content="@kylekloster" />
  <meta name="citation_author" content="Christopher Williams" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America" />
  <meta name="citation_author" content="Michael W. Nagle" />
  <meta name="citation_author_institution" content="Internal Medicine Research Unit, Pfizer Worldwide Research, Development, and Medical" />
  <meta name="citation_author_orcid" content="0000-0002-4677-7582" />
  <meta name="twitter:creator" content="@MikeNagle84" />
  <meta name="citation_author" content="Casey S. Greene" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America" />
  <meta name="citation_author_orcid" content="0000-0001-8713-9213" />
  <meta name="twitter:creator" content="@greenescientist" />
  <link rel="canonical" href="https://greenelab.github.io/xswap-manuscript/" />
  <meta property="og:url" content="https://greenelab.github.io/xswap-manuscript/" />
  <meta property="twitter:url" content="https://greenelab.github.io/xswap-manuscript/" />
  <meta name="citation_fulltext_html_url" content="https://greenelab.github.io/xswap-manuscript/" />
  <meta name="citation_pdf_url" content="https://greenelab.github.io/xswap-manuscript/manuscript.pdf" />
  <link rel="alternate" type="application/pdf" href="https://greenelab.github.io/xswap-manuscript/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://greenelab.github.io/xswap-manuscript/v/319566d1b277e231b6ae8a12fb793e7a391a3ad7/" />
  <meta name="manubot_html_url_versioned" content="https://greenelab.github.io/xswap-manuscript/v/319566d1b277e231b6ae8a12fb793e7a391a3ad7/" />
  <meta name="manubot_pdf_url_versioned" content="https://greenelab.github.io/xswap-manuscript/v/319566d1b277e231b6ae8a12fb793e7a391a3ad7/manuscript.pdf" />
  <meta property="og:type" content="article" />
  <meta property="twitter:card" content="summary_large_image" />
  <meta property="og:image" content="https://github.com/greenelab/xswap-manuscript/raw/319566d1b277e231b6ae8a12fb793e7a391a3ad7/thumbnail.png" />
  <meta property="twitter:image" content="https://github.com/greenelab/xswap-manuscript/raw/319566d1b277e231b6ae8a12fb793e7a391a3ad7/thumbnail.png" />
  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />
  <meta name="theme-color" content="#ad1457" />
  <!-- end Manubot generated metadata -->
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">The probability of edge existence due to node degree: a baseline for network-based predictions</h1>
</header>
<p><small><em>
This manuscript
(<a href="https://greenelab.github.io/xswap-manuscript/v/319566d1b277e231b6ae8a12fb793e7a391a3ad7/">permalink</a>)
was automatically generated
from <a href="https://github.com/greenelab/xswap-manuscript/tree/319566d1b277e231b6ae8a12fb793e7a391a3ad7">greenelab/xswap-manuscript@319566d</a>
on November 12, 2022.
</em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>Michael Zietz</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-0539-630X">0000-0003-0539-630X</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/zietzm">zietzm</a>
· <img src="images/twitter.svg" class="inline_icon" width="16" height="16" alt="Twitter icon" />
<a href="https://twitter.com/ZietzMichael">ZietzMichael</a>
<br>
<small>
Department of Physics &amp; Astronomy, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America; Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America
· Funded by Roy and Diana Vagelos Scholars Program in the Molecular Life Sciences; the Gordon and Betty Moore Foundation (GBMF4552)
</small></p></li>
<li><p><strong>Daniel S. Himmelstein</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-3012-7446">0000-0002-3012-7446</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/dhimmel">dhimmel</a>
· <img src="images/twitter.svg" class="inline_icon" width="16" height="16" alt="Twitter icon" />
<a href="https://twitter.com/dhimmel">dhimmel</a>
<br>
<small>
Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America
· Funded by Pfizer Worldwide Research, Development, and Medical; the Gordon and Betty Moore Foundation (GBMF4552)
</small></p></li>
<li><p><strong>Kyle Kloster</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-5678-7197">0000-0001-5678-7197</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/kkloste">kkloste</a>
· <img src="images/twitter.svg" class="inline_icon" width="16" height="16" alt="Twitter icon" />
<a href="https://twitter.com/kylekloster">kylekloster</a>
<br>
<small>
Department of Computer Science, North Carolina State University, Raleigh, North Carolina, United States of America
· Funded by the Gordon and Betty Moore Foundation (GBMF4560)
</small></p></li>
<li><p><strong>Christopher Williams</strong>
<br>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/chrsunwil">chrsunwil</a>
<br>
<small>
Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America
</small></p></li>
<li><p><strong>Michael W. Nagle</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-4677-7582">0000-0002-4677-7582</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/naglem">naglem</a>
· <img src="images/twitter.svg" class="inline_icon" width="16" height="16" alt="Twitter icon" />
<a href="https://twitter.com/MikeNagle84">MikeNagle84</a>
<br>
<small>
Internal Medicine Research Unit, Pfizer Worldwide Research, Development, and Medical
</small></p></li>
<li><p><strong>Casey S. Greene</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-8713-9213">0000-0001-8713-9213</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/cgreene">cgreene</a>
· <img src="images/twitter.svg" class="inline_icon" width="16" height="16" alt="Twitter icon" />
<a href="https://twitter.com/greenescientist">greenescientist</a>
<br>
<small>
Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America
· Funded by Pfizer Worldwide Research, Development, and Medical; the Gordon and Betty Moore Foundation (GBMF4552); the National Institutes of Health (R01 HG010067)
</small></p></li>
</ul>
<div id="correspondence">
<p>✉ — Correspondence possible via <a href="https://github.com/greenelab/xswap-manuscript/issues">GitHub Issues</a></p>
</div>
<h2 class="page_break_before" id="abstract">Abstract</h2>
<p>Important tasks in biomedical discovery such as predicting gene functions, gene-disease associations, and drug repurposing opportunities are often framed as network edge prediction.
The number of edges connecting to a node, termed degree, can vary greatly across nodes in real biomedical networks, and the distribution of degrees varies between networks.
If degree strongly influences edge prediction, then imbalance or bias in the distribution of degrees could lead to nonspecific or misleading predictions.
We introduce a network permutation framework to quantify the effects of node degree on edge prediction.
Our framework decomposes performance into the proportions attributable to degree and the network’s specific connections.
We discover that performance attributable to factors other than degree is often only a small portion of overall performance.
Degree’s predictive performance diminishes when the networks used for training and testing—despite measuring the same biological relationships—were generated using distinct techniques and hence have large differences in degree distribution.
We introduce the permutation-derived edge prior as the probability that an edge exists based only on degree.
The edge prior shows excellent discrimination and calibration for 20 biomedical networks (16 bipartite, 3 undirected, 1 directed), with AUROCs frequently exceeding 0.85.
Researchers seeking to predict new or missing edges in biological networks should use the edge prior as a baseline to identify the fraction of performance that is nonspecific because of degree.
We released our methods as an open-source Python package (https://github.com/hetio/xswap/).</p>
<h2 id="introduction">Introduction</h2>
<p>Networks contain information about relationships between entities (referred to here as “edges” between “nodes”).
A node’s degree is the number of edges it has in the network.
Networks contain many nodes, whose degrees can be aggregated to form the network’s degree distribution.
Because different nodes can have very different degrees, real networks have a variety of degree distributions (Figure <a href="#fig:hetionet">1</a>), and they commonly exhibit degree imbalance <span class="citation" data-cites="GFS9MouO hbOjmCsZ 1mIOnArF rly3gDig">[<a href="#ref-GFS9MouO" role="doc-biblioref">1</a>,<a href="#ref-hbOjmCsZ" role="doc-biblioref">2</a>,<a href="#ref-1mIOnArF" role="doc-biblioref">3</a>,<a href="#ref-rly3gDig" role="doc-biblioref">4</a>]</span>.
This is especially true for networks encoding biomedical knowledge or assays, where natural forces such as preferential attachment inherent to the problem domain combine with observation-based influences such as study methodology to create non-uniform degree distributions (Figure <a href="#fig:hetionet">1</a>).</p>
<div id="fig:hetionet" class="fignos">
<figure>
<img src="https://github.com/greenelab/xswap-analysis/raw/b0db22c82b2e58bf1ef5ae78317167982016e26b/img/hetionet_degrees.png" style="width:100.0%" alt="Figure 1: Biomedical networks are characterized by non-uniform degree distributions. Eight degree distributions are plotted for six edge types Hetionet v1.0 [5]. Hetionet integrates subnetworks for 24 different edge types, the degree distributions of which are analyzed separately. Furthermore, bipartite (e.g. Anatomy→expresses→Gene) and directed (e.g. Gene→regulates→Gene) graphs (Hetionet edge types) have both source and target degrees that must be assessed separately. Undirected edge types (e.g Compound–resembles–Compound) have only a single degree distribution. Degree distributions are non-uniform and vary greatly between different networks. The y-axis is log10-scaled to accommodate the common occurrence where most nodes have low degree while a small portion of nodes have high degree. Several distributions have nodes that reach the maximum degree, corresponding to a node being connected to all other possible nodes. Zero-degree nodes are not displayed, since methodological limitations often result in edge data only existing for a subset of nodes." />
<figcaption aria-hidden="true"><span>Figure 1:</span> <strong>Biomedical networks are characterized by non-uniform degree distributions.</strong>
Eight degree distributions are plotted for six edge types Hetionet v1.0 <span class="citation" data-cites="O21tn8vf">[<a href="#ref-O21tn8vf" role="doc-biblioref">5</a>]</span>.
Hetionet integrates subnetworks for 24 different edge types, the degree distributions of which are analyzed separately.
Furthermore, bipartite (e.g. Anatomy→expresses→Gene) and directed (e.g. Gene→regulates→Gene) graphs (Hetionet edge types) have both source and target degrees that must be assessed separately.
Undirected edge types (e.g Compound–resembles–Compound) have only a single degree distribution.
Degree distributions are non-uniform and vary greatly between different networks.
The y-axis is log<sub>10</sub>-scaled to accommodate the common occurrence where most nodes have low degree while a small portion of nodes have high degree.
Several distributions have nodes that reach the maximum degree, corresponding to a node being connected to all other possible nodes.
Zero-degree nodes are not displayed, since methodological limitations often result in edge data only existing for a subset of nodes.</figcaption>
</figure>
</div>
<p>Degree is an important metric for differentiating between nodes, and it appears in many common edge prediction features <span class="citation" data-cites="ohIv6zMA">[<a href="#ref-ohIv6zMA" role="doc-biblioref">6</a>]</span>.
However, reliance on degree can pose problems for edge prediction.
First, bias in networks can distort node degree so that a difference in degree between two nodes in a given network may not reflect a true difference in number of relationships.
Second, edge prediction methods that rely heavily on degree may be nonspecific—predicting trivial rather than insightful new relationships.</p>
<p>Most biomedical networks are imperfect representations of the true set of relationships.
Real networks often mistakenly include edges that do not exist and exclude edges that do exist.
How well a network represents the true relationships it attempts to represent depends on a number of factors, especially the methods used to generate the data in the network <span class="citation" data-cites="bo2VEmIz yJZSr6c6 C4FHCVCz">[<a href="#ref-bo2VEmIz" role="doc-biblioref">7</a>,<a href="#ref-yJZSr6c6" role="doc-biblioref">8</a>,<a href="#ref-C4FHCVCz" role="doc-biblioref">9</a>]</span>.
We define “degree bias” as the type of misrepresentation that occurs when the fraction of incorrectly existent/nonexistent relationships depends on a node’s degree.
Depending on the type of data being represented, degree biases can arise due to experimental methods, inspection bias, or other factors <span class="citation" data-cites="bo2VEmIz">[<a href="#ref-bo2VEmIz" role="doc-biblioref">7</a>]</span>.</p>
<p>Inspection bias indicates that entities are not uniformly studied <span class="citation" data-cites="lnDqu0oW">[<a href="#ref-lnDqu0oW" role="doc-biblioref">10</a>]</span>, and it is likely to cause degree bias when networks are constructed using hypothesis-driven findings extracted from the literature, as newly-discovered relationships are not randomly sampled from the set of all true relationships.
Though there is a high correlation between the number of publications mentioning a gene and its degree in low-throughput interaction networks, the number of publications mentioning a gene has little correlation with its degree in a systematically-derived protein interaction network <span class="citation" data-cites="LCyCrr7W">[Figure 6A in <a href="#ref-LCyCrr7W" role="doc-biblioref">11</a>]</span>.
This evidence suggests that many poorly studied genes have similar numbers of interactions as those scientists have preferentially examined and that these edges are missed due to inspection bias.
For networks with a large inspection bias, reliance on degree can lead to predictions that have good metrics when assessed by cross validation but little ability to generalize.</p>
<p>Another reason why a reliance on degree can be unfavorable is that degree imbalance can lead to prediction nonspecificity.
Nonspecific predictions are not made on the basis of the specific connectivity information contained in a network.
For example, Gillis et al. <span class="citation" data-cites="zB6RQrIj">[<a href="#ref-zB6RQrIj" role="doc-biblioref">12</a>]</span> examined the concept of prediction specificity in the context of gene function prediction and found that many predictions appear to rely primarily on multifunctionality and could be “potentially misleading with respect to causality.”
Degree imbalance leads high-degree nodes to dominate in the predictions made by degree-associated methods <span class="citation" data-cites="g059lh8v">[<a href="#ref-g059lh8v" role="doc-biblioref">13</a>]</span>, which are effective predictors of connections in some biological networks <span class="citation" data-cites="1736TBtF6">[<a href="#ref-1736TBtF6" role="doc-biblioref">14</a>]</span>.
Consequently, degree-based predictions are more likely nonspecific, meaning the same set of predictions performs well for different tasks.</p>
<p>Depending on the prediction task, edge predictions involving very high degree nodes may be undesired, uninsightful, or nonspecific.
While predictions based primarily on degree may be acceptable for some tasks, generating less obvious insights from networks requires drawing inferences from the specific connections and network structure between nodes.
Model evaluation is challenging in this context: nonspecific or trivial predictions can dominate performance evaluations and may actually be correct, even if they are not the desired outputs of the predictive model.
For example, predicting that the highest degree node in a network shares edges with the remaining nodes to which it is not connected will often lead to many correct predictions, despite this prediction being generic to all other nodes in the network.</p>
<p>Degree is important in edge prediction, but it can cause undesired effects.
Degree-based features should often be included in the interpretation of predictions to disentangle desired from non-desired effects and to effectively evaluate and compare predictive models.
We sought to directly measure the effect of node degree on edge prediction methods.
We introduce a permutation-based framework and software implementation to find edge existence probabilities due to node degree and to quantify the contribution of degree to edge prediction methods.
This method allows edge predictions to be evaluated in the context of degree and its effects on the prediction task.
Our results demonstrate that degree-associated methods are very effective for reconstructing a network using a subsampled holdout.
However, these methods are ineffective for predicting edges between networks measuring the same biological processes in targeted and systematic ways because such networks have distinct degree distributions.
Using multiple different networks, we provide evidence that degree has a strong effect on the probability of edge existence and that our permutation-based edge prior best quantifies this probability.</p>
<h2 id="methods">Methods</h2>
<h3 id="network-permutation">Network permutation</h3>
<p>Network permutation is a way to produce new networks by randomizing the connections of an existing network.
Specialized permutation strategies can be devised that randomize some aspects of networks while retaining other features.
Comparing between permuted and unpermuted networks gives insight to the effects of the retained network features.
For example, an edge prediction method that has superior reconstruction performance on a network compared to its permutations likely relies on information that is eliminated by permutation.
Conversely, identical predictive performance on true and permuted networks indicates that a method relies on information that is preserved during permutation.</p>
<p>Network permutation is a flexible framework for analyzing other methods, because it generates complete networks that can be analyzed independently.
We use network permutation to isolate degree and determine its effects in different contexts.
Degree-preserving network permutation obscures true connections and higher-order connectivity information (eg. community structure), while retaining node degree, and thereby, the network’s degree sequence.
Thanks to the flexibility of permutation, our framework can quantify the effect of degree on any network edge prediction method.</p>
<h3 id="xswap-algorithm">XSwap algorithm</h3>
<p>Hanhijärvi, et al. presented XSwap <span class="citation" data-cites="iKOIEzQ9">[<a href="#ref-iKOIEzQ9" role="doc-biblioref">15</a>]</span>, an algorithm for the randomization (“permutation”) of unweighted networks (Figure <a href="#fig:algo">2</a>A).
The algorithm picks two existing edges at random ({ab, cd}) and—if the edges constitute a valid swap—exchanges the targets between the edges ({ad, cb}; Supplemental Table <a href="#tbl:xswap">1</a>).
This process is repeated a user-specified number of times.
In general, the number of exchanges should be chosen to be sufficiently large that the fraction of original edges retained in the permuted network is near its asymptotic value as the number of exchanges increases to infinity.
The asymptotic fraction of original edges retained in permutation depends on network density, and higher density networks require more swap attempts per edge to reach their asymptotic fraction (Figure <a href="#fig:swap-percent">9</a>).</p>
<p>We modified the original XSwap algorithm by adding two parameters, <code>allow_loops</code> (a-a), and <code>allow_antiparallel</code> (a-b and b-a) that allow a greater variety of network types to be permuted (Figure <a href="#fig:algo">2</a>B and Supplemental Table <a href="#tbl:xswap">1</a>).
The motivation for these generalizations is to make the permutation method applicable both to directed and undirected graphs, as well as to networks with different types of nodes, variously called multipartite, heterogeneous, or multimodal networks.
Specifically, in the modified algorithm two chosen edges constitute a valid swap if they preserve degree for all four involved nodes and do not violate the user-specified parameters.</p>
<p>When permuting bipartite networks, our method ensures that each node’s class membership and within-class degree is preserved.
Similarly, heterogeneous networks should be permuted by considering each edge type as a separate network <span class="citation" data-cites="WkPlH1ds xmFxwmUd">[<a href="#ref-WkPlH1ds" role="doc-biblioref">16</a>,<a href="#ref-xmFxwmUd" role="doc-biblioref">17</a>]</span>.
This way, each node retains its within-edge-type degree for all edge types.
We provide documentation for parameter choices depending on the type of network being permuted in the GitHub repository (<a href="https://github.com/hetio/xswap" class="uri">https://github.com/hetio/xswap</a>).
The original algorithm and our proposed modification are given in Figure <a href="#fig:algo">2</a>.</p>
<div id="fig:algo" class="fignos">
<figure>
<img src="images/algorithms_label.png" style="width:65.0%" alt="Figure 2: XSwap algorithm pseudocode. A. XSwap algorithm presented by Hanhijärvi, et al. [15]. B. Extension of the XSwap algorithm to other types of networks." />
<figcaption aria-hidden="true"><span>Figure 2:</span> <strong>XSwap algorithm pseudocode.</strong>
<strong>A.</strong> XSwap algorithm presented by Hanhijärvi, et al. <span class="citation" data-cites="iKOIEzQ9">[<a href="#ref-iKOIEzQ9" role="doc-biblioref">15</a>]</span>.
<strong>B.</strong> Extension of the XSwap algorithm to other types of networks.</figcaption>
</figure>
</div>
<h3 id="edge-prior">Edge prior</h3>
<p>We introduce the edge prior to quantify the probability that two nodes are connected based only on their degree.
The edge prior can be estimated using the fraction of permuted networks in which a given edge exists—the maximum likelihood estimate for the binomial distribution success probability.
Based only on permuted networks, the edge prior does not contain any information about the true edges in the (unpermuted) network.
The edge prior is a numerical value that can be computed for every pair of nodes that could potentially share an edge; we compared its ability to predict edges in three tasks, discussed in <a href="#tasks">prediction tasks</a>.</p>
<h3 id="analytical-approximation-of-the-edge-prior">Analytical approximation of the edge prior</h3>
<p>Because network permutation can be computationally intensive, we also considered whether the probability of an edge existing across permuted networks has a simple closed-form expression.
We were unable to find a closed-form solution giving the edge prior without assuming that the probability of any given edge existing is independent of all other potential edges, which we believe is not valid for XSwap.
Nonetheless, we discovered a good analytical approximation to the edge prior that is particularly good for networks with many nodes and fewer edges (Figure <a href="#fig:approx-quality">3</a>).
Let <span class="math inline">\(m\)</span> be the total number of edges in the network, and <span class="math inline">\(u_i\)</span>, <span class="math inline">\(v_j\)</span> be the source and target degrees of a node pair, respectively.
An approximation of the edge prior is</p>
<p><span class="math display">\[
  P_{i,j} = \frac{u_i v_j}{\sqrt{(u_i v_j)^2 + (m - u_i - v_j + 1)^2}}.
\]</span></p>
<div id="fig:approx-quality" class="fignos">
<figure>
<img src="https://github.com/greenelab/xswap-analysis/raw/b0db22c82b2e58bf1ef5ae78317167982016e26b/img/prior_exact_vs_approx.png" style="width:100.0%" alt="Figure 3: The XSwap-derived edge prior can be analytically approximated. The analytical approximation is plotted against the XSwap-derived edge prior for three networks (edge types) from Hetionet. The strong correlation suggests that the approximation will be suitable for applications where computation time is a limiting factor." />
<figcaption aria-hidden="true"><span>Figure 3:</span> <strong>The XSwap-derived edge prior can be analytically approximated.</strong>
The analytical approximation is plotted against the XSwap-derived edge prior for three networks (edge types) from Hetionet.
The strong correlation suggests that the approximation will be suitable for applications where computation time is a limiting factor.</figcaption>
</figure>
</div>
<p>Further discussion of this approximate edge prior and an derivation are available in <a href="#approx-prior-supp">the supplement</a>.</p>
<h3 id="tasks">Prediction tasks</h3>
<p>We performed three prediction tasks to assess the performance of the edge prior.
We compared the permutation-based prior with two additional predictors: our analytical approximation of the edge prior and the product of source and target degree, scaled to the range [0, 1] so that we could assess its calibration as well as its discrimination.
We used 20 biomedical networks from the Hetionet heterogeneous network <span class="citation" data-cites="O21tn8vf">[<a href="#ref-O21tn8vf" role="doc-biblioref">5</a>]</span> that had at least 2000 edges for the first two tasks (<a href="#networks">Supplemental table</a>).
In the first task, we computed the degree-based predictors (edge prior, scaled degree product, and analytical prior approximation), and predicted the original edges in the network by rank-ordering node pair edge predictions by the node pairs’ predictor values.
We used node pairs that lacked an edge in the original network as negative examples and those with an edge as positive examples.
To assess the methods’ predictive performances, we computed the area under the receiver operating characteristic (AUROC) curve for all three predictors.
In the second task, we sampled 70% of edges from each of the networks, computed predictors on the sampled network, then predicted held-out edges.
For this task, negative examples were node pairs in which an edge did not exist in either original or sampled network, while positive samples were those node pairs without an edge in the sampled network but with an edge in the original network.</p>
<p>The third task evaluated the ability of the edge prior to generalize to new degree distributions.
We used two domains where networks were available which shared nodes but had different degree distributions.
Protein-protein interactions (PPI) and transcription factor-target gene (TF-TG) relationships had networks created both by literature curation of low-throughput, hypothesis-driven research and by high-throughput, systematic, hypothesis-free experimentation.
For the PPI networks, we used the STRING network, which incorporates literature-mining to find relationships <span class="citation" data-cites="fkKIuC7X">[<a href="#ref-fkKIuC7X" role="doc-biblioref">18</a>]</span> and a combination of the high-throughput, proteome-scale interaction networks from Rual et al. <span class="citation" data-cites="lnDqu0oW">[<a href="#ref-lnDqu0oW" role="doc-biblioref">10</a>]</span> and Rolland et al. <span class="citation" data-cites="LCyCrr7W">[<a href="#ref-LCyCrr7W" role="doc-biblioref">11</a>]</span>.
We used a transcription factor-target gene (TF-TG) literature-derived network from Han et al. <span class="citation" data-cites="z5ieI0Qg">[<a href="#ref-z5ieI0Qg" role="doc-biblioref">19</a>]</span> and a high-throughput network from Lachmann et al. <span class="citation" data-cites="13Jzku9hE">[<a href="#ref-13Jzku9hE" role="doc-biblioref">20</a>]</span>.
The pairs of networks for PPI and TF-TG data sources are ideal because in one we expect inspection bias and in the other we do not.</p>
<p>As a further basis of comparison, we added a time-resolved co-authorship network, which we partitioned by time to create two separate networks.
We created the co-authorship network of bioRxiv bioinformatics preprints using the Rxivist <span class="citation" data-cites="iPnRRJya 7668E40A">[<a href="#ref-iPnRRJya" role="doc-biblioref">21</a>,<a href="#ref-7668E40A" role="doc-biblioref">22</a>]</span> database, which was generated by crawling the bioRxiv server.
Unlike the other two networks, co-authorship does not have degree bias, as the network faithfully represents all true co-author relationships.
We include this network to offer a comparative prediction task in which the degree distributions between training (posted before 2018) and testing (posted during or after 2018) are not dramatically different (Figure <a href="#fig:degree-bias">4</a>A).
The goal of the third prediction task is to determine predictor generalizability for network reconstruction between different degree distributions, especially predicting a network without degree bias using predictors from a degree-biased network.
Further information about the networks used can be found in <a href="#networks">the supplement</a>.</p>
<h3 id="degree-grouping">Degree-grouping</h3>
<p>Our method for degree-preserving permutation produces randomized networks that share few of their edges with the original network.
The predictor values for two node pairs with the same source and target degree are drawn from the same distribution in permuted networks, so nodes with equal degree can be grouped when summarizing predictors.
For a given node pair, degree grouping treats other node pairs with the same degrees as additional permutations.
We used this strategy to augment the number of predictor values for each node pair in permuted networks, allowing node pairs to have more permuted predictor values than permuted networks.
Degree grouping greatly increased the effective number of permutations for nodes with frequently observed degrees <span class="citation" data-cites="DwbABa00">[<a href="#ref-DwbABa00" role="doc-biblioref">23</a>]</span>.
We used degree grouping throughout our analyses.</p>
<h3 id="implementation-and-source-code">Implementation and source code</h3>
<p>We implemented our modified version of the XSwap algorithm as an open-source Python package.
The package contains modules for permuting networks, computing the edge prior, and converting networks between adjacency matrix and edge list formats.
Additionally, we include the analytical approximation of the edge prior and functionality to assign unique identifiers to nodes.
The Python package is <a href="https://pypi.org/project/xswap/">available</a> on the Python Packaging Index under the name “xswap”.
The full source code is freely available under the BSD 2-Clause License (<a href="https://github.com/hetio/xswap" class="uri">https://github.com/hetio/xswap</a>).</p>
<p>The edge swap mechanism—implemented in C++ for greater speed—uses a bitset to avoid producing edges which violate the conditions for a valid swap.
While the full bitset implementation is faster for smaller networks, our package uses a compressed bitset <span class="citation" data-cites="jNEBDktj">[<a href="#ref-jNEBDktj" role="doc-biblioref">24</a>]</span> when a network would occupy memory above a user-adjustable threshold.
In addition to the validity conditions already described, our package allows specific edges to be excluded from permutation, and every network permutation returns both a permuted network and summary information about the numbers of swaps attempted, performed, and the reasons why invalid swaps were rejected.</p>
<p>In addition to the Python package, all code to generate the analyses and figures is available at <a href="https://github.com/greenelab/xswap-analysis" class="uri">https://github.com/greenelab/xswap-analysis</a>.
The manuscript was written using the Manubot software <span class="citation" data-cites="YuJbg3zO">[<a href="#ref-YuJbg3zO" role="doc-biblioref">25</a> ]</span>, which allows anyone to provide feedback or modifications via the public repository at <a href="https://github.com/greenelab/xswap-manuscript" class="uri">https://github.com/greenelab/xswap-manuscript</a>.</p>
<h2 id="results">Results</h2>
<h3 id="node-degree-bias-is-prevalent">Node degree bias is prevalent</h3>
<p>We found examples of node degree bias in the PPI and TF-TG networks we investigated.
Figure <a href="#fig:degree-bias">4</a> shows node degree in separate networks for the same type of data.
For the PPI networks, the literature-derived network has a larger mean degree and a longer tail than the systematic network, while in the TF-TG networks this relationship is reversed.
Because the TF-TG network contained far more transcription factors than target genes (144 and 1406, respectively), the distributions of target degrees were far more compact than those of source degrees.
Unlike the PPI and TF-TG networks, the co-authorship networks were split by date of first co-authorship and did not exhibit a great difference in their degree distributions.
All three types of networks (PPI, TF-TG, and co-authorship) exhibit degree imbalance to varying extents.
These results indicate that, depending on the methods by which the represented data were generated, networks of the same type of data may have overall degree distributions that differ greatly (Figure <a href="#fig:degree-bias">4</a>A), and they may even assign very different degree to the same nodes (Figure <a href="#fig:degree-bias">4</a>B).</p>
<div id="fig:degree-bias" class="fignos">
<figure>
<img src="https://github.com/greenelab/xswap-analysis/raw/d7181e64a5c90f9720ab453334892aba164651e7/img/degree_bias.png" style="width:100.0%" alt="Figure 4: A. Degree distributions of networks with and without degree bias can be very different. Data on PPI and TF-TG were split between literature-derived and systematically-derived networks. In both cases, the networks exhibit large differences in degree distribution. Co-authorship relationship networks split by date of first co-authorship roughly share their degree distributions. B. Comparison of individual node degrees between different networks. Not only are the overall degree distributions different, but individual nodes can have systematically different degrees between two networks. Uniform random sampling produces linearly-correlated node degree, while non-random sampling produces non-correlated degree. Systematically-derived networks are not uniformly sampled from literature-derived networks or vice versa. 70% of literature edges were sampled with uniform probability for the “Subsampled holdout” network." />
<figcaption aria-hidden="true"><span>Figure 4:</span> <strong>A.</strong> Degree distributions of networks with and without degree bias can be very different.
Data on PPI and TF-TG were split between literature-derived and systematically-derived networks.
In both cases, the networks exhibit large differences in degree distribution.
Co-authorship relationship networks split by date of first co-authorship roughly share their degree distributions.
<strong>B.</strong> Comparison of individual node degrees between different networks.
Not only are the overall degree distributions different, but individual nodes can have systematically different degrees between two networks.
Uniform random sampling produces linearly-correlated node degree, while non-random sampling produces non-correlated degree.
Systematically-derived networks are not uniformly sampled from literature-derived networks or vice versa.
70% of literature edges were sampled with uniform probability for the “Subsampled holdout” network.</figcaption>
</figure>
</div>
<h3 id="the-edge-prior-encapsulates-degree">The edge prior encapsulates degree</h3>
<p>In the first prediction task, we computed three predictors—the XSwap edge prior, an analytical approximation to the edge prior, and the (scaled) product of source and target node degree—on networks from Hetionet.
We then evaluated the extent to which these predictors—treated as predictions themselves—could reconstruct the 20 networks (<a href="#networks">Supplemental table</a>).
The XSwap-derived edge prior reconstructed many of the networks with a high level of performance, as measured by the AUROC.
Of the 20 individual networks we extracted from Hetionet, 17 had an edge prior self-reconstruction AUROC &gt;= 0.95, with the highest reconstruction AUROC at 0.9971 (network was the Compound–downregulates–Gene edge type).
Meanwhile, the lowest self-reconstruction performance (AUROC = 0.7697) occurred in the network having the fewest node pairs (network was the Disease–localizes–Anatomy edge type).</p>
<div id="fig:discrimination" class="fignos">
<figure>
<img src="https://github.com/greenelab/xswap-analysis/raw/c763473ee83c6157f2430bf9a64b19dc564b7dbc/img/auroc.png" style="width:60.0%" alt="Figure 5: Degree can predict edges within a given network but does not generalize to networks with different degree distributions The edge prior is able to reconstruct the networks on which it was computed (Task 1, “unsampled”, 20 different networks) with high performance. When computed on a sampled network, the edge prior can reconstruct the unsampled network with slightly lower performance (Task 2, “sampled”, 20 different networks). However, when computed on a completely different network (having a different degree distribution) of the same type of data, the edge prior’s performance is greatly reduced (Task 3, “separate”, 3 different networks). The performance reduction from computing predictors on sampled networks is real but far smaller compared to a new degree distribution. This indicates that while degree can be effective for network reconstruction, it is far less effective in predicting edges from a different degree distribution." />
<figcaption aria-hidden="true"><span>Figure 5:</span> <strong>Degree can predict edges within a given network but does not generalize to networks with different degree distributions</strong>
The edge prior is able to reconstruct the networks on which it was computed (Task 1, “unsampled”, 20 different networks) with high performance.
When computed on a sampled network, the edge prior can reconstruct the unsampled network with slightly lower performance (Task 2, “sampled”, 20 different networks).
However, when computed on a completely different network (having a different degree distribution) of the same type of data, the edge prior’s performance is greatly reduced (Task 3, “separate”, 3 different networks).
The performance reduction from computing predictors on sampled networks is real but far smaller compared to a new degree distribution.
This indicates that while degree can be effective for network reconstruction, it is far less effective in predicting edges from a different degree distribution.</figcaption>
</figure>
</div>
<p>The three predictors that we compared were highly correlated (Spearman rank correlation over 0.984 for all 20 networks).
The three predictors also had very similar AUROC reconstruction performance values for the first, second, and third prediction tasks (max difference &lt; 0.027) because AUROC is rank-based.
The edge prior was slightly better than the approximations in 12 of 20 networks.
However, while the AUROC results were similar, the predictors were very different in their levels of calibration—the ability of the model to correctly estimate edge existence probabilities.
The edge prior was very well calibrated for all networks in the first and second tasks, and it provided the best calibration of the three predictors for each of the prediction tasks (Figure <a href="#fig:calibration">6</a>A).
As the edge prior was not based on the networks’ true edges, these results indicated that degree sequence alone was highly informative and that permutation was the only approach in our comparison that provided a well-calibrated model.</p>
<div id="fig:calibration" class="fignos">
<figure>
<img src="https://github.com/zietzm/xswap-analysis/raw/c763473ee83c6157f2430bf9a64b19dc564b7dbc/img/fig4.calibration.png" style="width:100.0%" alt="Figure 6: The edge prior accurately assigns the probability of edge existence. A. Calibration curves for full network reconstruction of 20 networks from Hetionet. For every unique predictor value on the horizontal axis, the fraction of node pairs with that predictor value having an edge in the network is shown on the vertical axis. The permutation-based edge prior’s calibration was superior to the other two strategies based on degree. B. Calibration curves for sampled network reconstruction. The edge prior shows superior calibration in the 20 Hetionet networks. C. Individual Hetionet edge type calibration estimated by the two-component decomposition of the Brier score, in which lower scores indicate better calibration. The edge prior has excellent calibration in unsampled and sampled networks, and each considered method is sensitive to shifts in the degree distribution." />
<figcaption aria-hidden="true"><span>Figure 6:</span> <strong>The edge prior accurately assigns the probability of edge existence.</strong>
<strong>A.</strong> Calibration curves for full network reconstruction of 20 networks from Hetionet.
For every unique predictor value on the horizontal axis, the fraction of node pairs with that predictor value having an edge in the network is shown on the vertical axis.
The permutation-based edge prior’s calibration was superior to the other two strategies based on degree.
<strong>B.</strong> Calibration curves for sampled network reconstruction.
The edge prior shows superior calibration in the 20 Hetionet networks.
<strong>C.</strong> Individual Hetionet edge type calibration estimated by the two-component decomposition of the Brier score, in which lower scores indicate better calibration.
The edge prior has excellent calibration in unsampled and sampled networks, and each considered method is sensitive to shifts in the degree distribution.</figcaption>
</figure>
</div>
<p>The second prediction task mirrored the first task, but it involved reconstructing networks based on subsampled networks with only 70% of the original edges.
Because edges were sampled uniformly without replacement, the subsampled networks share similar degree distributions to the original networks (see Figure <a href="#fig:degree-bias">4</a>B).
Unlike in the first task, edges that were present in the sampled network were not tested and therefore are not included in the performance metrics.
The results of the second prediction task further demonstrate a high level of performance for degree-sequence-based node pair predictors (Figure <a href="#fig:discrimination">5</a>).
The edge prior was able to reconstruct the unsampled network with an AUROC of greater than 0.9 in 14 of 20 networks.
As was observed in the first task, node pair predictors computed in the second task were highly rank-correlated, meaning the AUROC values for different predictors were similar.
While performance was slightly lower in the second task than the first, many networks were still well-reconstructed.
The edge prior was the best calibrated predictor for both tasks.</p>
<p>In the third prediction task, we computed the three edge predictors for paired networks representing data from PPI, TF-TG, and bioRxiv bioinformatics pre-print co-authorship.
The goal of the task was to compare predictive performance across different degree distributions for the same type of data.
We find that the task of predicting systematically-derived edges using a network with degree bias is significantly more challenging than network reconstruction, and we find consistently lower performance compared to the other tasks (Figure <a href="#fig:discrimination">5</a>).
The edge prior was not able to predict the separate PPI network better than by random guessing (AUROC of roughly 0.5).
Only slightly better was its performance in predicting the separate TF-TG network, at an AUROC of 0.59.
We find superior performance in predicting the co-authorship relationships (AUROC 0.75), which was expected as the network being predicted shared roughly the same degree distribution as the network on which the edge prior was computed.
The results of the third prediction task show that a difference in degree distribution between the network on which predictors are computed and the network to be predicted can make prediction significantly more challenging.</p>
<p>The edge prior can be considered a baseline edge predictor that accurately captures degree’s contribution to the probability of an edge existing.
The edge prior’s low performance in the third task indicates that degree is less helpful for edge prediction tasks in which training and testing networks do not share their degree distributions.
Many biomedical prediction tasks can be framed as edge prediction tasks between different degree distributions.
In drug repurposing, for example, existing compound-disease treatment relationships are unlikely to be randomly sampled from all true treatment relationships.
However, all treatment relationships between existing compounds and diseases are desirable outputs in prediction.
Edge predictions can be based on both underlying biological properties and network degree distributions.
However, predictions based on biological properties may be more consistent and generalizable than those based on degree.
Degree’s influence on edge prediction accuracy measures can reveal the relative contributions of these two factors.</p>
<h3 id="degree-can-underly-a-large-fraction-of-performance">Degree can underly a large fraction of performance</h3>
<p>We conducted a further edge prediction task as an example application of the edge prior and our permutation framework.
To begin, we chose the STRING PPI network for the comparison and computed five edge prediction features (Supplemental table <a href="#tbl:edge-prediction">2</a>).
The goal of the task was to reconstruct the network on which the features were computed.
All five features were correlated with degree (Figure <a href="#fig:feature-degree">7</a>), which we quantified for a node pair using the product of source and target degrees.
We expected features based on degree to show strong performance for a network reconstruction task without holdout, as found in the first prediction task.</p>
<div id="fig:feature-degree" class="fignos">
<figure>
<img src="https://github.com/greenelab/xswap-analysis/raw/f8dce1983243fd4056108c7c8bdcba895f6dfbaf/img/feature-degree.png" style="width:100.0%" alt="Figure 7: Common edge-prediction metrics correlate with node degree. Five common edge-prediction features (Supplemental table 2) are correlated with node degree on the STRING PPI network [18]. All five features show a positive relationship with degree, though the magnitude of this correlation is highly variable. The preferential attachment index is understandably perfectly correlated because it is equal to the product of source and target degree. Each panel indicates the Pearson correlation (“r”) between feature and degree in the lower right corner." />
<figcaption aria-hidden="true"><span>Figure 7:</span> <strong>Common edge-prediction metrics correlate with node degree.</strong>
Five common edge-prediction features (Supplemental table <a href="#tbl:edge-prediction">2</a>) are correlated with node degree on the STRING PPI network <span class="citation" data-cites="fkKIuC7X">[<a href="#ref-fkKIuC7X" role="doc-biblioref">18</a>]</span>.
All five features show a positive relationship with degree, though the magnitude of this correlation is highly variable.
The preferential attachment index is understandably perfectly correlated because it is equal to the product of source and target degree.
Each panel indicates the Pearson correlation (“r”) between feature and degree in the lower right corner.</figcaption>
</figure>
</div>
<p>We used two permutation-derived null values to evaluate reconstruction and contextualize performance.
First, the performance of the edge prior was compared to determine the performance attributable to the degree sequence of the PPI network.
The first comparison gave insight into the ability of the PPI network to be reconstructed by degree.
Second, the five edge prediction features were computed on 100 permuted networks and used to reconstruct the unpermuted network.
Each permuted network corresponded to AUROC values quantifying the performances of features computed on it.
The second comparison gave insight into the performance of each feature if the feature was only capturing degree.</p>
<div id="fig:feature-auroc" class="fignos">
<figure>
<img src="https://github.com/greenelab/xswap-analysis/raw/4d9137f43a16fbe6c6a02865adceaa9a3195fe2d/img/feature-auroc.png" style="width:85.0%" alt="Figure 8: Identifying the fraction of a metric’s performance resulting from degree alone. Network reconstruction performances by five edge prediction features. Dotted red line indicates performance of the edge prior. Each feature was computed on both the unpermuted and 100 permutations of the STRING PPI network." />
<figcaption aria-hidden="true"><span>Figure 8:</span> <strong>Identifying the fraction of a metric’s performance resulting from degree alone.</strong>
Network reconstruction performances by five edge prediction features.
Dotted red line indicates performance of the edge prior.
Each feature was computed on both the unpermuted and 100 permutations of the STRING PPI network.</figcaption>
</figure>
</div>
<p>The edge prior encapsulates nonspecific predictions due to degree, and it reconstructed the PPI network with an AUROC of 0.797 (dotted red line in Figure <a href="#fig:feature-auroc">8</a>).
In the second comparison, edge prediction features computed on permuted networks had performance equal or lower to their performances on the unpermuted networks.
This indicated that four out of five edge prediction features discern more than node degree for the prediction task.
The preferential attachment index is the product of source and target degree, and its performance did not differ from the edge prior or the feature’s performance when computed on permuted networks.</p>
<p>This comparison quantified the performance of degree toward the prediction task and assessed degree’s effect on five edge prediction features.
The edge prior provided the baseline level of performance attributable to degree alone.
Comparing the performances on permuted networks to the performance of the edge prior reveals the extent to which a feature measures degree.
Features whose performances on permuted networks were below that of the edge prior only imperfectly measured degree (eg: Jaccard index), whereas features whose performances equaled the edge prior completely captured degree (eg: preferential attachment index).
Features can also capture information beyond degree, and our method can quantify this performance.
For example, the superior performance on unpermuted networks relative to permuted networks indicated that RWR, resource allocation, Jaccard, and Adamic/Adar indices captured more than degree in this prediction task.
These results aligned with the definitions of each feature and validated that our permutation framework accurately assessed reliance on degree.</p>
<h2 id="discussion">Discussion</h2>
<p>We focus on edge prediction in biomedical networks.
Our overall goal is to predict new edges with specificity, so that predictions reflect particular connectivity rather than generic node characteristics.
Our permutation framework measures the predictive performance attributable to degree to provide a baseline expectation for edge pairs.
We expect that non-specificity due to degree is not a unique property of biomedical networks.
For example, if node A connects to nearly all other nodes in a network, predicting that all remaining nodes share an edge with node A will likely result in many correct—though nonspecific—predictions, regardless of the type of data contained in the network.
Node degree should be accounted for to make correct predictions while being able to distinguish specific from nonspecific predictions.
Prediction without reliance on node degree is challenging because many effective methods for edge prediction are correlated with degree (Figure <a href="#fig:feature-degree">7</a>).</p>
<p>The effects of node degree are obvious when edge prediction features are functions of degree.
For example, the resource allocation index is the sum of inverse degree of common neighbors between source and target nodes (in the symmetric case), while preferential attachment is the product of source and target degree <span class="citation" data-cites="1F96bsjSm suzIn5oo">[<a href="#ref-1F96bsjSm" role="doc-biblioref">26</a>,<a href="#ref-suzIn5oo" role="doc-biblioref">27</a>]</span>.
However, because many other edge prediction methods are not explicitly degree-based, it is important to have a general method for comparing the effects of node degree on edge prediction methods.</p>
<p>We developed a permutation framework to quantify the edge probability due to degree.
We term this probability the “edge prior”, and we have identified two applications.
First, a probability associated with every node pair can be treated as a classification score.
Ordering these scores provides an assessment of performance based solely on degree, which can be used as a baseline for other classifiers.
Second, node pair probabilities can be used to adjust edge prediction features depending on the task.
If degree is a desired feature, then the edge prior can be treated like a Bayesian prior probability.
Alternatively, if degree is not a desired feature, then the edge prior can be used to calibrate features and thus potentially enhance predictive specificity.</p>
<p>Figure <a href="#fig:feature-auroc">8</a> illustrates the utility of the edge prior and permutation framework for two purposes.
First, it contextualizes feature performances relative to the baseline of nonspecific, degree-based predictions, quantified by the edge prior.
Degree has varying utility for different edge prediction tasks.
The edge prior’s performance on a task quantifies the utility of degree toward the task.
This comparison is useful because specific predictions (based on more than degree alone) are more valuable for some applications than nonspecific ones and because degree can be an expression of bias in many real-world networks.</p>
<p>Second, Figure <a href="#fig:feature-auroc">8</a> compares five edge prediction features computed on and unpermuted networks.
This comparison identified the fraction of each feature’s performance attributable to degree.
Some features, such as the preferential attachment index, perfectly and exclusively measure degree.
The Adamic/Adar index also almost completely captures degree because its performances from permuted networks are nearly at the performance of the edge prior.
However, the Adamic/Adar index had much higher performance when computed on the unpermuted network, indicating that it also extracts higher-order information.
This analysis, enabled by network permutation, measured the extent to which features rely on degree for a specific prediction task by assessing performance beyond the degree-based, nonspecific baseline.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We developed a network permutation framework and open source software implementation that quantifies the probability of edge existence due to degree and can assess the fraction of feature performance attributable to degree.
We demonstrated the superiority of the edge prior over other degree-based features for quantifying the effect of degree on the probability of edge existence.
The XSwap methods and software provide a context for evaluating edge prediction methods and specific predictions for reliance on degree and, therefore, nonspecificity.
Network edge prediction is a common task in biological and biomedical research, and it can be greatly influenced by degree.
Degree should be considered directly in prediction approaches to avoid making nonspecific or trivial predictions due to degree imbalance or bias.
A careful accounting of degree’s effects enables contextualized model evaluation and can help to quantify nonspecificity in biomedical network edge prediction.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>The authors thank <a href="https://orcid.org/0000-0001-7720-6208">Blair Sullivan</a> for <a href="https://github.com/greenelab/xswap-manuscript/issues/54">her feedback</a> on a draft of the manuscript.</p>
<h2 class="page_break_before" id="references">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-GFS9MouO" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline"><strong>Biology, Methodology or Chance? The Degree Distributions of Bipartite Ecological Networks</strong> <div class="csl-block">Richard J Williams</div> <em>PLoS ONE</em> (2011-03-03) <a href="https://doi.org/fmtk6x">https://doi.org/fmtk6x</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pone.0017645">10.1371/journal.pone.0017645</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21390231">21390231</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3048397">PMC3048397</a></div></div>
</div>
<div id="ref-hbOjmCsZ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline"><strong>The Degree Distribution of Networks: Statistical Model Selection</strong> <div class="csl-block">William P Kelly, Piers J Ingram, Michael PH Stumpf</div> <em>Bacterial Molecular Networks</em> (2011-10-28) <a href="https://doi.org/ddx5rx">https://doi.org/ddx5rx</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/978-1-61779-361-5_13">10.1007/978-1-61779-361-5_13</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22144157">22144157</a></div></div>
</div>
<div id="ref-1mIOnArF" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline"><strong>Scale-free networks are rare</strong> <div class="csl-block">Anna D Broido, Aaron Clauset</div> <em>Nature Communications</em> (2019-03-04) <a href="https://doi.org/gfztz9">https://doi.org/gfztz9</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41467-019-08746-5">10.1038/s41467-019-08746-5</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30833554">30833554</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6399239">PMC6399239</a></div></div>
</div>
<div id="ref-rly3gDig" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline"><strong>Emergence of Scaling in Random Networks</strong> <div class="csl-block">Albert-László Barabási, Réka Albert</div> <em>Science</em> (1999-10-15) <a href="https://doi.org/ccsmnz">https://doi.org/ccsmnz</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.286.5439.509">10.1126/science.286.5439.509</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/10521342">10521342</a></div></div>
</div>
<div id="ref-O21tn8vf" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline"><strong>Systematic integration of biomedical knowledge prioritizes drugs for repurposing</strong> <div class="csl-block">Daniel Scott Himmelstein, Antoine Lizee, Christine Hessler, Leo Brueggeman, Sabrina L Chen, Dexter Hadley, Ari Green, Pouya Khankhanian, Sergio E Baranzini</div> <em>eLife</em> (2017-09-22) <a href="https://doi.org/cdfk">https://doi.org/cdfk</a> <div class="csl-block">DOI: <a href="https://doi.org/10.7554/elife.26726">10.7554/elife.26726</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28936969">28936969</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5640425">PMC5640425</a></div></div>
</div>
<div id="ref-ohIv6zMA" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline"><strong>Link Prediction Methods and Their Accuracy for Different Social Networks and Network Metrics</strong> <div class="csl-block">Fei Gao, Katarzyna Musial, Colin Cooper, Sophia Tsoka</div> <em>Scientific Programming</em> (2015) <a href="https://doi.org/f7hvd9">https://doi.org/f7hvd9</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1155/2015/172879">10.1155/2015/172879</a></div></div>
</div>
<div id="ref-bo2VEmIz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline"><strong>Bias tradeoffs in the creation and analysis of protein–protein interaction networks</strong> <div class="csl-block">Jesse Gillis, Sara Ballouz, Paul Pavlidis</div> <em>Journal of Proteomics</em> (2014-04) <a href="https://doi.org/f3mn5f">https://doi.org/f3mn5f</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jprot.2014.01.020">10.1016/j.jprot.2014.01.020</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24480284">24480284</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3972268">PMC3972268</a></div></div>
</div>
<div id="ref-yJZSr6c6" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline"><strong>Correcting for the study bias associated with protein–protein interaction measurements reveals differences between protein degree distributions from different cancer types</strong> <div class="csl-block">Martin H Schaefer, Luis Serrano, Miguel A Andrade-Navarro</div> <em>Frontiers in Genetics</em> (2015-08-04) <a href="https://doi.org/gf5t46">https://doi.org/gf5t46</a> <div class="csl-block">DOI: <a href="https://doi.org/10.3389/fgene.2015.00260">10.3389/fgene.2015.00260</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26300911">26300911</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4523822">PMC4523822</a></div></div>
</div>
<div id="ref-C4FHCVCz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline"><strong>Effect of sampling on topology predictions of protein-protein interaction networks</strong> <div class="csl-block">Jing-Dong J Han, Denis Dupuy, Nicolas Bertin, Michael E Cusick, Marc Vidal</div> <em>Nature Biotechnology</em> (2005-07) <a href="https://doi.org/dj5cm8">https://doi.org/dj5cm8</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/nbt1116">10.1038/nbt1116</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/16003372">16003372</a></div></div>
</div>
<div id="ref-lnDqu0oW" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline"><strong>Towards a proteome-scale map of the human protein–protein interaction network</strong> <div class="csl-block">Jean-François Rual, Kavitha Venkatesan, Tong Hao, Tomoko Hirozane-Kishikawa, Amélie Dricot, Ning Li, Gabriel F Berriz, Francis D Gibbons, Matija Dreze, Nono Ayivi-Guedehoussou, … Marc Vidal</div> <em>Nature</em> (2005-09-28) <a href="https://doi.org/dw6q23">https://doi.org/dw6q23</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/nature04209">10.1038/nature04209</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/16189514">16189514</a></div></div>
</div>
<div id="ref-LCyCrr7W" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline"><strong>A Proteome-Scale Map of the Human Interactome Network</strong> <div class="csl-block">Thomas Rolland, Murat Taşan, Benoit Charloteaux, Samuel J Pevzner, Quan Zhong, Nidhi Sahni, Song Yi, Irma Lemmens, Celia Fontanillo, Roberto Mosca, … Marc Vidal</div> <em>Cell</em> (2014-11) <a href="https://doi.org/f3mn6x">https://doi.org/f3mn6x</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.cell.2014.10.050">10.1016/j.cell.2014.10.050</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25416956">25416956</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4266588">PMC4266588</a></div></div>
</div>
<div id="ref-zB6RQrIj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">12. </div><div class="csl-right-inline"><strong>The Impact of Multifunctional Genes on "Guilt by Association" Analysis</strong> <div class="csl-block">Jesse Gillis, Paul Pavlidis</div> <em>PLoS ONE</em> (2011-02-18) <a href="https://doi.org/bs9">https://doi.org/bs9</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pone.0017258">10.1371/journal.pone.0017258</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21364756">21364756</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041792">PMC3041792</a></div></div>
</div>
<div id="ref-g059lh8v" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">13. </div><div class="csl-right-inline"><strong>Addressing false discoveries in network inference</strong> <div class="csl-block">Tobias Petri, Stefan Altmann, Ludwig Geistlinger, Ralf Zimmer, Robert Küffner</div> <em>Bioinformatics</em> (2015-04-24) <a href="https://doi.org/f7rwgt">https://doi.org/f7rwgt</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btv215">10.1093/bioinformatics/btv215</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25910697">25910697</a></div></div>
</div>
<div id="ref-1736TBtF6" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">14. </div><div class="csl-right-inline"><strong>Evidence of probabilistic behaviour in protein interaction networks</strong> <div class="csl-block">Joseph Ivanic, Anders Wallqvist, Jaques Reifman</div> <em>BMC Systems Biology</em> (2008-01-31) <a href="https://doi.org/dsz4kn">https://doi.org/dsz4kn</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/1752-0509-2-11">10.1186/1752-0509-2-11</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/18237403">18237403</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2267158">PMC2267158</a></div></div>
</div>
<div id="ref-iKOIEzQ9" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">15. </div><div class="csl-right-inline"><strong>Randomization Techniques for Graphs</strong> <div class="csl-block">Sami Hanhijärvi, Gemma C Garriga, Kai Puolamäki</div> <em>Proceedings of the 2009 SIAM International Conference on Data Mining</em> (2009-04-30) <a href="https://doi.org/f3mn58">https://doi.org/f3mn58</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1137/1.9781611972795.67">10.1137/1.9781611972795.67</a></div></div>
</div>
<div id="ref-WkPlH1ds" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">16. </div><div class="csl-right-inline"><strong>Heterogeneous Network Edge Prediction: A Data Integration Approach to Prioritize Disease-Associated Genes</strong> <div class="csl-block">Daniel S Himmelstein, Sergio E Baranzini</div> <em>PLOS Computational Biology</em> (2015-07-09) <a href="https://doi.org/98q">https://doi.org/98q</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pcbi.1004259">10.1371/journal.pcbi.1004259</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26158728">26158728</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4497619">PMC4497619</a></div></div>
</div>
<div id="ref-xmFxwmUd" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">17. </div><div class="csl-right-inline"><strong>Permuting hetnets and implementing randomized edge swaps in cypher</strong> <div class="csl-block">Daniel Himmelstein</div> <em>ThinkLab</em> (2015-12-21) <a href="https://doi.org/f3mqt6">https://doi.org/f3mqt6</a> <div class="csl-block">DOI: <a href="https://doi.org/10.15363/thinklab.d136">10.15363/thinklab.d136</a></div></div>
</div>
<div id="ref-fkKIuC7X" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">18. </div><div class="csl-right-inline"><strong>STRING v11: protein–protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets</strong> <div class="csl-block">Damian Szklarczyk, Annika L Gable, David Lyon, Alexander Junge, Stefan Wyder, Jaime Huerta-Cepas, Milan Simonovic, Nadezhda T Doncheva, John H Morris, Peer Bork, … Christian von Mering</div> <em>Nucleic Acids Research</em> (2018-11-22) <a href="https://doi.org/gfz2jr">https://doi.org/gfz2jr</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gky1131">10.1093/nar/gky1131</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30476243">30476243</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6323986">PMC6323986</a></div></div>
</div>
<div id="ref-z5ieI0Qg" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">19. </div><div class="csl-right-inline"><strong>TRRUST v2: an expanded reference database of human and mouse transcriptional regulatory interactions</strong> <div class="csl-block">Heonjong Han, Jae-Won Cho, Sangyoung Lee, Ayoung Yun, Hyojin Kim, Dasom Bae, Sunmo Yang, Chan Yeong Kim, Muyoung Lee, Eunbeen Kim, … Insuk Lee</div> <em>Nucleic Acids Research</em> (2017-10-26) <a href="https://doi.org/gcwpcz">https://doi.org/gcwpcz</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkx1013">10.1093/nar/gkx1013</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29087512">29087512</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5753191">PMC5753191</a></div></div>
</div>
<div id="ref-13Jzku9hE" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">20. </div><div class="csl-right-inline"><strong>ChEA: transcription factor regulation inferred from integrating genome-wide ChIP-X experiments</strong> <div class="csl-block">Alexander Lachmann, Huilei Xu, Jayanth Krishnan, Seth I Berger, Amin R Mazloom, Avi Ma'ayan</div> <em>Bioinformatics</em> (2010-08-13) <a href="https://doi.org/d2h98v">https://doi.org/d2h98v</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btq466">10.1093/bioinformatics/btq466</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20709693">20709693</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2944209">PMC2944209</a></div></div>
</div>
<div id="ref-iPnRRJya" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">21. </div><div class="csl-right-inline"><strong>Tracking the popularity and outcomes of all bioRxiv preprints</strong> <div class="csl-block">Richard J Abdill, Ran Blekhman</div> <em>eLife</em> (2019-04-24) <a href="https://doi.org/gf2str">https://doi.org/gf2str</a> <div class="csl-block">DOI: <a href="https://doi.org/10.7554/elife.45133">10.7554/elife.45133</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31017570">31017570</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6510536">PMC6510536</a></div></div>
</div>
<div id="ref-7668E40A" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">22. </div><div class="csl-right-inline"><strong>Complete Rxivist dataset of scraped bioRxiv data</strong> <div class="csl-block">Richard J Abdill, Ran Blekhman</div> <em>Zenodo</em> (2019-03-21) <a href="https://doi.org/gfz3fm">https://doi.org/gfz3fm</a> <div class="csl-block">DOI: <a href="https://doi.org/10.5281/zenodo.2566421">10.5281/zenodo.2566421</a></div></div>
</div>
<div id="ref-DwbABa00" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">23. </div><div class="csl-right-inline"><strong>Degree-grouped permutations by zietzm · Pull Request #96 · greenelab/connectivity-search-analyses</strong> <div class="csl-block">GitHub</div> <a href="https://github.com/greenelab/connectivity-search-analyses/pull/96">https://github.com/greenelab/connectivity-search-analyses/pull/96</a></div>
</div>
<div id="ref-jNEBDktj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">24. </div><div class="csl-right-inline"><strong>Roaring Bitmaps: Implementation of an Optimized Software Library</strong> <div class="csl-block">Daniel Lemire, Owen Kaser, Nathan Kurz, Luca Deri, Chris O'Hara, François Saint-Jacques, Gregory Ssi-Yan-Kai</div> <em>arXiv</em> (2022-02-08) <a href="https://arxiv.org/abs/1709.07821">https://arxiv.org/abs/1709.07821</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1002/spe.2560">10.1002/spe.2560</a></div></div>
</div>
<div id="ref-YuJbg3zO" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">25. </div><div class="csl-right-inline"><strong>Open collaborative writing with Manubot</strong> <div class="csl-block">Daniel S Himmelstein, Vincent Rubinetti, David R Slochower, Dongbo Hu, Venkat S Malladi, Casey S Greene, Anthony Gitter</div> <em>PLOS Computational Biology</em> (2019-06-24) <a href="https://doi.org/c7np">https://doi.org/c7np</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pcbi.1007128">10.1371/journal.pcbi.1007128</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31233491">31233491</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6611653">PMC6611653</a></div></div>
</div>
<div id="ref-1F96bsjSm" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">26. </div><div class="csl-right-inline"><strong>Predicting missing links via local information</strong> <div class="csl-block">Tao Zhou, Linyuan Lü, Yi-Cheng Zhang</div> <em>The European Physical Journal B</em> (2009-10) <a href="https://doi.org/dd55vr">https://doi.org/dd55vr</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1140/epjb/e2009-00335-8">10.1140/epjb/e2009-00335-8</a></div></div>
</div>
<div id="ref-suzIn5oo" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">27. </div><div class="csl-right-inline"><strong>Link prediction approach to collaborative filtering</strong> <div class="csl-block">Zan Huang, Xin Li, Hsinchun Chen</div> <em>Proceedings of the 5th ACM/IEEE-CS joint conference on Digital libraries - JCDL '05</em> (2005) <a href="https://doi.org/fn39g8">https://doi.org/fn39g8</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1145/1065385.1065415">10.1145/1065385.1065415</a></div></div>
</div>
<div id="ref-EfWvuSjX" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">28. </div><div class="csl-right-inline"><strong>The link-prediction problem for social networks</strong> <div class="csl-block">David Liben-Nowell, Jon Kleinberg</div> <em>Journal of the American Society for Information Science and Technology</em> (2007) <a href="https://doi.org/c56765">https://doi.org/c56765</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1002/asi.20591">10.1002/asi.20591</a></div></div>
</div>
<div id="ref-9dBDcARP" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">29. </div><div class="csl-right-inline"><strong>Friends and neighbors on the Web</strong> <div class="csl-block">Lada A Adamic, Eytan Adar</div> <em>Social Networks</em> (2003-07) <a href="https://doi.org/br5zd3">https://doi.org/br5zd3</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/s0378-8733(03)00009-1">10.1016/s0378-8733(03)00009-1</a></div></div>
</div>
<div id="ref-HSmvOV9E" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">30. </div><div class="csl-right-inline"><strong>Automatic multimedia cross-modal correlation discovery</strong> <div class="csl-block">Jia-Yu Pan, Hyung-Jeong Yang, Christos Faloutsos, Pinar Duygulu</div> <em>Proceedings of the 2004 ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '04</em> (2004) <a href="https://doi.org/bmhgw4">https://doi.org/bmhgw4</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1145/1014052.1014135">10.1145/1014052.1014135</a></div></div>
</div>
<div id="ref-1E6tdJtDz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">31. </div><div class="csl-right-inline"><strong>Learning with local and global consistency</strong> <div class="csl-block">Dengyong Zhou, Olivier Bousquet, Thomas Navin Lal, Jason Weston, Bernhard Scholkopf</div> <em>NIPS 2003</em> (2003-12-09) <a href="https://dl.acm.org/doi/10.5555/2981345.2981386">https://dl.acm.org/doi/10.5555/2981345.2981386</a></div>
</div>
<div id="ref-1EgqwD4S1" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">32. </div><div class="csl-right-inline"><strong>Link prediction in large directed graphs</strong> <div class="csl-block">Dario Garcia Gasulla</div> <em>Universitat Politècnica de Catalunya</em> (2015-04-23) <a href="https://upcommons.upc.edu/handle/2117/95691">https://upcommons.upc.edu/handle/2117/95691</a></div>
</div>
</div>
<h2 id="supplemental-information">Supplemental information</h2>
<h3 id="xswap-parameter-settings-for-network-types">XSwap parameter settings for network types</h3>
<div id="tbl:xswap" class="tablenos">
<table id="tbl:xswap">
<caption><span>Table 1:</span> Applications of the modified XSwap algorithm to various network types with appropriate parameter choices.
For simple networks, each node’s degree is preserved.
For bipartite networks, each node’s number of connections to the other part is preserved, and the partite sets (node class memberships) are preserved.
For directed networks, each nodes’ in- and out-degrees are preserved, though parameter choices depend on the network being permuted.
Some directed networks can include antiparallel edges or loops while others do not. </caption>
<colgroup>
<col style="width: 16%" />
<col style="width: 22%" />
<col style="width: 8%" />
<col style="width: 27%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Network type</th>
<th style="text-align: left;">Degree preserved</th>
<th style="text-align: left;">Figure</th>
<th style="text-align: left;"><code>allow_antiparallel</code></th>
<th style="text-align: left;"><code>allow_loops</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">simple</td>
<td style="text-align: left;">all</td>
<td style="text-align: left;"><img src="images/xswap_simple.png" title="fig:" height="85" /></td>
<td style="text-align: left;">False</td>
<td style="text-align: left;">False</td>
</tr>
<tr class="even">
<td style="text-align: left;">directed</td>
<td style="text-align: left;">in/out</td>
<td style="text-align: left;"><img src="images/xswap_directed.png" title="fig:" height="85" /></td>
<td style="text-align: left;">Depends on networks</td>
<td style="text-align: left;">Depends on networks</td>
</tr>
<tr class="odd">
<td style="text-align: left;">bipartite</td>
<td style="text-align: left;">Depends on directedness</td>
<td style="text-align: left;"><img src="images/xswap_bipartite.png" title="fig:" height="85" /></td>
<td style="text-align: left;">True</td>
<td style="text-align: left;">True</td>
</tr>
</tbody>
</table>
</div>
<h3 id="performance-of-the-xswap-algorithm">Performance of the XSwap algorithm</h3>
<p>The performance of the XSwap algorithm depends on a number of network properties.
We define network density to be the number of edges divided by the number of potential edges.
Increasing network density lowers the asymptotic fraction of edges changed, as greater density prevents the algorithm from removing certain edges.
Random graphs generated with a preferential attachment mechanism (via Barabási–Albert) can have a lower fraction of their edges swapped, asymptotically, as compared to uniform random graphs (via Erdős–Rényi).</p>
<div id="fig:swap-percent" class="fignos">
<figure>
<img src="https://github.com/greenelab/xswap-analysis/raw/47f67f85b1a5df2714d564c274515f1fdeb882ba/img/6_xswap_percent_swapped_iterations/lines_continuous.png" style="width:100.0%" alt="Figure 9: Higher density networks have lower asymptotic fractions of edges swapped and take more attempts to reach these values. The Barabási–Albert model produces scale-free random graphs, while Erdős–Rényi generates random graphs where all edges are equally likely." />
<figcaption aria-hidden="true"><span>Figure 9:</span> Higher density networks have lower asymptotic fractions of edges swapped and take more attempts to reach these values.
The Barabási–Albert model produces scale-free random graphs, while Erdős–Rényi generates random graphs where all edges are equally likely.</figcaption>
</figure>
</div>
<h3 id="approx-prior-supp">Approximate edge prior</h3>
<p>To approximate the edge prior, we began by making two simplifications.
First, we assumed independence between node pairs.
This assumption does not actually hold for the XSwap algorithm, though it is a reasonable simplification for large, sparse networks.
Second, we assumed that the XSwap process is stationary.
This assumption also does not actually hold, but it was made because it significantly simplifies the problem.
A single node pair has two possible states, “edge” and “no edge”.
These states are not transient, and they are not periodic so long as more than one possible swap exists in the network.
In almost all cases, then, our simplified model of the algorithm gives the state of a node pair as an ergodic process, independent of other node pairs.</p>
<p>Let <span class="math inline">\(A_{i,j}\)</span> represent the existence of edge <span class="math inline">\((i, j)\)</span>
For a given node pair, <span class="math inline">\((i, j)\)</span>, then, let <span class="math inline">\(q_{i,j}\)</span> represent the transition probability from the “no edge” state to the “edge” state in one successful iteration of the XSwap algorithm.
Let <span class="math inline">\(r_{i,j}\)</span> represent the probability of the opposite transition (“edge” to “no edge”) in one successful iteration.
With “no edge” represented as <span class="math inline">\([1, 0]^T\)</span> and “edge” represented as <span class="math inline">\([0, 1]^T\)</span>, the transition matrix, <span class="math inline">\(P\)</span>, is given by the following:</p>
<p><span class="math display">\[\begin{align*}
    P^T &amp;= \begin{bmatrix}
       1-q &amp; r \\
       q &amp; 1-r
     \end{bmatrix}
\end{align*}\]</span></p>
<p>The stationary distribution of this system should correspond to the distribution when the number of swaps goes to infinity.
It can be found by computing the eigenvectors of the system, as we know that the stationary distribution vector, <span class="math inline">\(\mathbf{v}\)</span> satisfies <span class="math inline">\(P^T \mathbf{v} = \mathbf{v}\)</span>.
The eigenvector <span class="math inline">\(\mathbf{v}\)</span>, normalized to sum to 1 as a probability vector, is given by</p>
<p><span class="math display">\[\begin{align*}
    \mathbf{v} = \frac{1}{r + q} \begin{bmatrix}
        r \\
        q
    \end{bmatrix}
\end{align*}\]</span></p>
<p>The asymptotic edge probability is therefore</p>
<p><span class="math display">\[\frac{q}{r + q}.\]</span></p>
<p>Since node pairs are being treated as independent, the probability of an edge being created in one successful iteration, given that the edge does not currently exist, is the ratio of the number of edge choices involving nodes <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> to the total number of possible swaps, <span class="math inline">\(S\)</span>.
Let <span class="math inline">\(d(u_i)\)</span> represent the degree of source node <span class="math inline">\(i\)</span> and <span class="math inline">\(d(v_j)\)</span> represent the degree of target node <span class="math inline">\(j\)</span>.</p>
<p><span class="math display">\[q_{i,j} = \frac{d(u_i)d(v_j)}{S}\]</span></p>
<p>Similarly, the probability of an edge being eliminated in one iteration is the ratio of the number of edge choices involving <span class="math inline">\((i,j)\)</span> and any other valid edge to the total number of possible swaps.
Let <span class="math inline">\(m\)</span> be the total number of edges in the network.</p>
<p><span class="math display">\[r_{i,j} = \frac{m - d(u_i) - d(v_j) + 1}{S}\]</span></p>
<p>The approximate edge prior is, therefore,</p>
<p><span class="math display">\[\frac{d(u_i)d(v_j)}{m - d(u_i) - d(v_j) + 1 + d(u_i)d(v_j)}.\]</span></p>
<p>Unfortunately, we found that the above edge prior approximation is a poor approximation in many cases.
We found that the following modified form (introduced in Methods) affords a superior approximation:</p>
<p><span class="math display">\[\begin{equation}
    P_{i,j} = \frac{d(u_i) d(v_j)}{\sqrt{(d(u_i) d(v_j))^2 + (m - d(u_i) - d(v_j) + 1)^2}}
\end{equation}\]</span></p>
<p>Interestingly, this expression can be derived by normalizing the eigenvector <span class="math inline">\(\mathbf{v}\)</span> to be a unit vector in the 2-norm instead of the 1-norm; that is, we use the value <span class="math inline">\(q / \sqrt{r^2 + q^2}\)</span> instead of <span class="math inline">\(q/(r+q)\)</span>.
Because the modified form of the approximation offers a much superior fit to the data, we chose to include only the modified version in the released Python package, and we used the modified form throughout our analysis.</p>
<h3 id="networks">Networks used for comparison</h3>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border-width:1px;border-style:solid;border-color:#ccc;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}
.tg .tg-buh4{background-color:#f9f9f9;text-align:left;vertical-align:top}
.tg .tg-mrzz{background-color:#f9f9f9;text-align:left}
.tg .tg-s268{text-align:left}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style>
<table class="tg">
<tr>
<th class="tg-s268">
Data
</th>
<th class="tg-s268">
Network
</th>
<th class="tg-s268">
Nodes
</th>
<th class="tg-0lax">
Edges
</th>
</tr>
<tr>
<td class="tg-s268" rowspan="20">
Hetionet
</td>
<td class="tg-mrzz">
AdG
</td>
<td class="tg-mrzz">
Source: 402, Target: 20945
</td>
<td class="tg-buh4">
102240
</td>
</tr>
<tr>
<td class="tg-s268">
AeG
</td>
<td class="tg-s268">
Source: 402, Target: 20945
</td>
<td class="tg-0lax">
526407
</td>
</tr>
<tr>
<td class="tg-mrzz">
AlD
</td>
<td class="tg-mrzz">
Source: 402, Target: 137
</td>
<td class="tg-buh4">
3602
</td>
</tr>
<tr>
<td class="tg-s268">
AuG
</td>
<td class="tg-s268">
Source: 402, Target: 20945
</td>
<td class="tg-0lax">
97848
</td>
</tr>
<tr>
<td class="tg-mrzz">
BPpG
</td>
<td class="tg-mrzz">
Source: 11381, Target: 20945
</td>
<td class="tg-buh4">
559504
</td>
</tr>
<tr>
<td class="tg-s268">
CCpG
</td>
<td class="tg-s268">
Source: 1391, Target: 20945
</td>
<td class="tg-0lax">
73566
</td>
</tr>
<tr>
<td class="tg-mrzz">
CbG
</td>
<td class="tg-mrzz">
Source: 1552, Target: 20945
</td>
<td class="tg-buh4">
11571
</td>
</tr>
<tr>
<td class="tg-s268">
CcSE
</td>
<td class="tg-s268">
Source: 1552, Target: 5734
</td>
<td class="tg-0lax">
138944
</td>
</tr>
<tr>
<td class="tg-mrzz">
CdG
</td>
<td class="tg-mrzz">
Source: 1552, Target: 20945
</td>
<td class="tg-buh4">
21102
</td>
</tr>
<tr>
<td class="tg-s268">
CrC
</td>
<td class="tg-s268">
1552
</td>
<td class="tg-0lax">
6486
</td>
</tr>
<tr>
<td class="tg-mrzz">
CuG
</td>
<td class="tg-mrzz">
Source: 1552, Target: 20945
</td>
<td class="tg-buh4">
18756
</td>
</tr>
<tr>
<td class="tg-s268">
DaG
</td>
<td class="tg-s268">
Source: 137, Target: 20945
</td>
<td class="tg-0lax">
12623
</td>
</tr>
<tr>
<td class="tg-mrzz">
DdG
</td>
<td class="tg-mrzz">
Source: 137, Target: 20945
</td>
<td class="tg-buh4">
7623
</td>
</tr>
<tr>
<td class="tg-s268">
DpS
</td>
<td class="tg-s268">
Source: 137, Target: 438
</td>
<td class="tg-0lax">
3357
</td>
</tr>
<tr>
<td class="tg-mrzz">
DuG
</td>
<td class="tg-mrzz">
Source: 137, Target: 20945
</td>
<td class="tg-buh4">
7731
</td>
</tr>
<tr>
<td class="tg-s268">
GuG
</td>
<td class="tg-s268">
20945
</td>
<td class="tg-0lax">
265672
</td>
</tr>
<tr>
<td class="tg-mrzz">
GcG
</td>
<td class="tg-mrzz">
20945
</td>
<td class="tg-buh4">
61690
</td>
</tr>
<tr>
<td class="tg-s268">
GiG
</td>
<td class="tg-s268">
20945
</td>
<td class="tg-0lax">
147164
</td>
</tr>
<tr>
<td class="tg-mrzz">
GpMF
</td>
<td class="tg-mrzz">
Source: 20945, Target: 2884
</td>
<td class="tg-buh4">
97222
</td>
</tr>
<tr>
<td class="tg-s268">
GpPW
</td>
<td class="tg-s268">
Source: 20945, Target: 1822
</td>
<td class="tg-0lax">
84372
</td>
</tr>
<tr>
<td class="tg-mrzz" rowspan="3">
PPI
</td>
<td class="tg-mrzz">
Sampled
</td>
<td class="tg-mrzz">
3992
</td>
<td class="tg-buh4">
255522
</td>
</tr>
<tr>
<td class="tg-s268">
Literature
</td>
<td class="tg-s268">
3992
</td>
<td class="tg-0lax">
364743
</td>
</tr>
<tr>
<td class="tg-mrzz">
Systematic
</td>
<td class="tg-mrzz">
3916
</td>
<td class="tg-buh4">
12913
</td>
</tr>
<tr>
<td class="tg-s268" rowspan="3">
bioRxiv
</td>
<td class="tg-s268">
Sampled
</td>
<td class="tg-s268">
4587
</td>
<td class="tg-0lax">
30686
</td>
</tr>
<tr>
<td class="tg-mrzz">
&lt;2018
</td>
<td class="tg-mrzz">
4615
</td>
<td class="tg-buh4">
43691
</td>
</tr>
<tr>
<td class="tg-s268">
All time
</td>
<td class="tg-s268">
4615
</td>
<td class="tg-0lax">
44963
</td>
</tr>
<tr>
<td class="tg-buh4" rowspan="3">
TF-TG
</td>
<td class="tg-mrzz">
Sampled
</td>
<td class="tg-mrzz">
Source: 142, Target: 1396
</td>
<td class="tg-buh4">
2689
</td>
</tr>
<tr>
<td class="tg-s268">
Literature
</td>
<td class="tg-s268">
Source: 144, Target: 1406
</td>
<td class="tg-0lax">
3496
</td>
</tr>
<tr>
<td class="tg-mrzz">
Systematic
</td>
<td class="tg-mrzz">
Source: 144, Target: 1417
</td>
<td class="tg-buh4">
29177
</td>
</tr>
</table>
<h3 id="edge-prediction-features">Edge prediction features</h3>
<p>In the table that follows, let <span class="math inline">\(k(u)\)</span> denote the set of neighbors of node <span class="math inline">\(u\)</span>.
Let <span class="math inline">\(\mathbf{A}\)</span> represent the normalized Laplacian adjacency matrix, and let <span class="math inline">\(y_u\)</span> be a vector with all ones except for a one in the <span class="math inline">\(u\)</span>-th position.
<span class="math inline">\(x\)</span>
For a directed graph, let <span class="math inline">\(A(u)\)</span> denote the set of nodes that node <span class="math inline">\(u\)</span> points to and <span class="math inline">\(D(u)\)</span> the set of nodes that point to <span class="math inline">\(u\)</span>.
All definitions that follow are the score between nodes <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span>.</p>
<div id="tbl:edge-prediction" class="tablenos">
<table id="tbl:edge-prediction" style="width:100%;">
<caption><span>Table 2:</span> Edge prediction features. </caption>
<colgroup>
<col style="width: 47%" />
<col style="width: 41%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Definition</th>
<th>Citation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Jaccard index</td>
<td><span class="math inline">\(\frac{|k(u) \cap k(v)|}{|k(u) \cup k(v)|}\)</span></td>
<td><span class="citation" data-cites="EfWvuSjX">[<a href="#ref-EfWvuSjX" role="doc-biblioref">28</a>]</span></td>
</tr>
<tr class="even">
<td>Preferential attachment score</td>
<td><span class="math inline">\(|k(u)||k(v)|\)</span></td>
<td><span class="citation" data-cites="EfWvuSjX">[<a href="#ref-EfWvuSjX" role="doc-biblioref">28</a>]</span></td>
</tr>
<tr class="odd">
<td>Resource allocation index</td>
<td><span class="math inline">\(\sum_{w \in k(u) \cap k(v)} \frac{1}{|k(w)|}\)</span></td>
<td><span class="citation" data-cites="1F96bsjSm">[<a href="#ref-1F96bsjSm" role="doc-biblioref">26</a>]</span></td>
</tr>
<tr class="even">
<td>Adamic/Adar index</td>
<td><span class="math inline">\(\sum_{w \in k(u) \cap k(v)} \frac{1}{log|k(w)|}\)</span></td>
<td><span class="citation" data-cites="9dBDcARP">[<a href="#ref-9dBDcARP" role="doc-biblioref">29</a>]</span></td>
</tr>
<tr class="odd">
<td>Random walk with restart score</td>
<td><span class="math inline">\(c \bigg[ \bigg( \mathbb{I} - (1-c) \mathbf{A}\bigg)^{-1} \mathbf{y}_u \bigg]_v\)</span></td>
<td><span class="citation" data-cites="HSmvOV9E 1E6tdJtDz">[<a href="#ref-HSmvOV9E" role="doc-biblioref">30</a>,<a href="#ref-1E6tdJtDz" role="doc-biblioref">31</a>]</span></td>
</tr>
<tr class="even">
<td>Inference score</td>
<td><span class="math inline">\(\frac{|A(u) \cap D(v)|}{|A(u)|} + \frac{|D(u) \cap D(v)|}{|D(u)|}\)</span></td>
<td><span class="citation" data-cites="1EgqwD4S1">[<a href="#ref-1EgqwD4S1" role="doc-biblioref">32</a>]</span></td>
</tr>
</tbody>
</table>
</div>
<!-- default theme -->

<style>
  /* import google fonts */
  @import url("https://fonts.googleapis.com/css?family=Open+Sans:400,600,700");
  @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

  /* -------------------------------------------------- */
  /* global */
  /* -------------------------------------------------- */

  /* all elements */
  * {
    /* force sans-serif font unless specified otherwise */
    font-family: "Open Sans", "Helvetica", sans-serif;

    /* prevent text inflation on some mobile browsers */
    -webkit-text-size-adjust: none !important;
    -moz-text-size-adjust: none !important;
    -o-text-size-adjust: none !important;
    text-size-adjust: none !important;
  }

  @media only screen {
    /* "page" element */
    body {
      position: relative;
      box-sizing: border-box;
      font-size: 12pt;
      line-height: 1.5;
      max-width: 8.5in;
      margin: 20px auto;
      padding: 40px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* "page" element */
    body {
      padding: 20px;
      margin: 0;
      border-radius: 0;
      border: none;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
      background: none;
    }
  }

  /* -------------------------------------------------- */
  /* headings */
  /* -------------------------------------------------- */

  /* all headings */
  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    margin: 20px 0;
    padding: 0;
    font-weight: bold;
  }

  /* biggest heading */
  h1 {
    margin: 40px 0;
    text-align: center;
  }

  /* second biggest heading */
  h2 {
    margin-top: 30px;
    padding-bottom: 5px;
    border-bottom: solid 1px #bdbdbd;
  }

  /* heading font sizes */
  h1 {
    font-size: 2em;
  }
  h2 {
    font-size: 1.5em;
  }
  h3 {
    font-size: 1.35em;
  }
  h4 {
    font-size: 1.25em;
  }
  h5 {
    font-size: 1.15em;
  }
  h6 {
    font-size: 1em;
  }

  /* -------------------------------------------------- */
  /* manuscript header */
  /* -------------------------------------------------- */

  /* manuscript title */
  header > h1 {
    margin: 0;
  }

  /* manuscript title caption text (ie "automatically generated on") */
  header + p {
    text-align: center;
    margin-top: 10px;
  }

  /* -------------------------------------------------- */
  /* text elements */
  /* -------------------------------------------------- */

  /* links */
  a {
    color: #2196f3;
    overflow-wrap: break-word;
  }

  /* superscripts and subscripts */
  sub,
  sup {
    /* prevent from affecting line height */
    line-height: 0;
  }

  /* unordered and ordered lists*/
  ul,
  ol {
    padding-left: 20px;
  }

  /* class for styling text semibold */
  .semibold {
    font-weight: 600;
  }

  /* class for styling elements horizontally left aligned */
  .left {
    display: block;
    text-align: left;
    margin-left: auto;
    margin-right: 0;
    justify-content: left;
  }

  /* class for styling elements horizontally centered */
  .center {
    display: block;
    text-align: center;
    margin-left: auto;
    margin-right: auto;
    justify-content: center;
  }

  /* class for styling elements horizontally right aligned */
  .right {
    display: block;
    text-align: right;
    margin-left: 0;
    margin-right: auto;
    justify-content: right;
  }

  /* -------------------------------------------------- */
  /* section elements */
  /* -------------------------------------------------- */

  /* horizontal divider line */
  hr {
    border: none;
    height: 1px;
    background: #bdbdbd;
  }

  /* paragraphs, horizontal dividers, figures, tables, code */
  p,
  hr,
  figure,
  table,
  pre {
    /* treat all as "paragraphs", with consistent vertical margins */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* figures */
  /* -------------------------------------------------- */

  /* figure */
  figure {
    max-width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure caption */
  figcaption {
    padding: 0;
    padding-top: 10px;
  }

  /* figure image element */
  figure > img,
  figure > svg {
    max-width: 100%;
    display: block;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure auto-number */
  img + figcaption > span:first-of-type,
  svg + figcaption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* tables */
  /* -------------------------------------------------- */

  /* table */
  table {
    border-collapse: collapse;
    border-spacing: 0;
    width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* table cells */
  th,
  td {
    border: solid 1px #bdbdbd;
    padding: 10px;
    /* squash table if too wide for page by forcing line breaks */
    overflow-wrap: break-word;
    word-break: break-word;
  }

  /* header row and even rows */
  th,
  tr:nth-child(2n) {
    background-color: #fafafa;
  }

  /* odd rows */
  tr:nth-child(2n + 1) {
    background-color: #ffffff;
  }

  /* table caption */
  caption {
    text-align: left;
    padding: 0;
    padding-bottom: 10px;
  }

  /* table auto-number */
  table > caption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* code */
  /* -------------------------------------------------- */

  /* multi-line code block */
  pre {
    padding: 10px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
    break-inside: avoid;
    text-align: left;
  }

  /* inline code, ie code within normal text */
  :not(pre) > code {
    padding: 0 4px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
  }

  /* code text */
  /* apply all children, to reach syntax highlighting sub-elements */
  code,
  code * {
    /* force monospace font */
    font-family: "Source Code Pro", "Courier New", monospace;
  }

  /* -------------------------------------------------- */
  /* quotes */
  /* -------------------------------------------------- */

  /* quoted text */
  blockquote {
    margin: 0;
    padding: 0;
    border-left: 4px solid #bdbdbd;
    padding-left: 16px;
    break-inside: avoid;
  }

  /* -------------------------------------------------- */
  /* banners */
  /* -------------------------------------------------- */

  /* info banners */
  .banner {
    box-sizing: border-box;
    display: block;
    position: relative;
    width: 100%;
    margin-top: 20px;
    margin-bottom: 20px;
    padding: 20px;
    text-align: center;
  }

  /* paragraph in banner */
  .banner > p {
    margin: 0;
  }

  /* -------------------------------------------------- */
  /* highlight colors */
  /* -------------------------------------------------- */

  .white {
    background: #ffffff;
  }
  .lightgrey {
    background: #eeeeee;
  }
  .grey {
    background: #757575;
  }
  .darkgrey {
    background: #424242;
  }
  .black {
    background: #000000;
  }
  .lightred {
    background: #ffcdd2;
  }
  .lightyellow {
    background: #ffecb3;
  }
  .lightgreen {
    background: #dcedc8;
  }
  .lightblue {
    background: #e3f2fd;
  }
  .lightpurple {
    background: #f3e5f5;
  }
  .red {
    background: #f44336;
  }
  .orange {
    background: #ff9800;
  }
  .yellow {
    background: #ffeb3b;
  }
  .green {
    background: #4caf50;
  }
  .blue {
    background: #2196f3;
  }
  .purple {
    background: #9c27b0;
  }
  .white,
  .lightgrey,
  .lightred,
  .lightyellow,
  .lightgreen,
  .lightblue,
  .lightpurple,
  .orange,
  .yellow,
  .white a,
  .lightgrey a,
  .lightred a,
  .lightyellow a,
  .lightgreen a,
  .lightblue a,
  .lightpurple a,
  .orange a,
  .yellow a {
    color: #000000;
  }
  .grey,
  .darkgrey,
  .black,
  .red,
  .green,
  .blue,
  .purple,
  .grey a,
  .darkgrey a,
  .black a,
  .red a,
  .green a,
  .blue a,
  .purple a {
    color: #ffffff;
  }

  /* -------------------------------------------------- */
  /* buttons */
  /* -------------------------------------------------- */

  /* class for styling links like buttons */
  .button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    margin: 5px;
    padding: 10px 20px;
    font-size: 0.75em;
    font-weight: 600;
    text-transform: uppercase;
    text-decoration: none;
    letter-spacing: 1px;
    background: none;
    color: #2196f3;
    border: solid 1px #bdbdbd;
    border-radius: 5px;
  }

  /* buttons when hovered */
  .button:hover:not([disabled]),
  .icon_button:hover:not([disabled]) {
    cursor: pointer;
    background: #f5f5f5;
  }

  /* buttons when disabled */
  .button[disabled],
  .icon_button[disabled] {
    opacity: 0.35;
    pointer-events: none;
  }

  /* class for styling buttons containg only single icon */
  .icon_button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    text-decoration: none;
    margin: 0;
    padding: 0;
    background: none;
    border-radius: 5px;
    border: none;
    width: 20px;
    height: 20px;
    min-width: 20px;
    min-height: 20px;
  }

  /* icon button inner svg image */
  .icon_button > svg {
    height: 16px;
  }

  /* -------------------------------------------------- */
  /* icons */
  /* -------------------------------------------------- */

  /* class for styling icons inline with text */
  .inline_icon {
    height: 1em;
    position: relative;
    top: 0.125em;
  }

  /* -------------------------------------------------- */
  /* references */
  /* -------------------------------------------------- */

  .csl-entry {
    margin-top: 15px;
    margin-bottom: 15px;
  }

  /* -------------------------------------------------- */
  /* print control */
  /* -------------------------------------------------- */

  @media print {
    @page {
      /* suggested printing margin */
      margin: 0.5in;
    }

    /* document and "page" elements */
    html,
    body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
    }

    /* "page" element */
    body {
      font-size: 11pt !important;
      line-height: 1.35;
    }

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      margin: 15px 0;
    }

    /* figures and tables */
    figure,
    table {
      font-size: 0.85em;
    }

    /* table cells */
    th,
    td {
      padding: 5px;
    }

    /* shrink font awesome icons */
    i.fas,
    i.fab,
    i.far,
    i.fal {
      transform: scale(0.85);
    }

    /* decrease banner margins */
    .banner {
      margin-top: 15px;
      margin-bottom: 15px;
      padding: 15px;
    }

    /* class for centering an element vertically on its own page */
    .page_center {
      margin: auto;
      width: 100%;
      height: 100%;
      display: flex;
      align-items: center;
      vertical-align: middle;
      break-before: page;
      break-after: page;
    }

    /* always insert a page break before the element */
    .page_break_before {
      break-before: page;
    }

    /* always insert a page break after the element */
    .page_break_after {
      break-after: page;
    }

    /* avoid page break before the element */
    .page_break_before_avoid {
      break-before: avoid;
    }

    /* avoid page break after the element */
    .page_break_after_avoid {
      break-after: avoid;
    }

    /* avoid page break inside the element */
    .page_break_inside_avoid {
      break-inside: avoid;
    }
  }

  /* -------------------------------------------------- */
  /* override pandoc css quirks */
  /* -------------------------------------------------- */

  .sourceCode {
    /* prevent unsightly overflow in wide code blocks */
    overflow: auto !important;
  }

  div.sourceCode {
    /* prevent background fill on top-most code block  container */
    background: none !important;
  }

  .sourceCode * {
    /* force consistent line spacing */
    line-height: 1.5 !important;
  }

  div.sourceCode {
    /* style code block margins same as <pre> element */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* tablenos */
  /* -------------------------------------------------- */

  /* tablenos wrapper */
  .tablenos {
    width: 100%;
    margin: 20px 0;
  }

  .tablenos > table {
    /* move margins from table to table_wrapper to allow margin collapsing */
    margin: 0;
  }

  @media only screen {
    /* tablenos wrapper */
    .tablenos {
      /* show scrollbar on tables if necessary to prevent overflow */
      overflow-x: auto !important;
    }

    .tablenos th,
    .tablenos td {
      overflow-wrap: unset !important;
      word-break: unset !important;
    }

    /* table in wrapper */
    .tablenos table,
    .tablenos table * {
      /* don't break table words */
      overflow-wrap: normal !important;
    }
  }
</style>
<!-- 
    Plugin Core

    Functions needed for and shared across all first-party plugins.
-->

<script>
  // get element that is target of hash (from link element or url)
  function getHashTarget(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector(`[id="${id}"]`);
    if (!target) return;

    // if figure or table, modify target to get expected element
    if (id.indexOf("fig:") === 0) target = target.querySelector("figure");
    if (id.indexOf("tbl:") === 0) target = target.querySelector("table");

    return target;
  }

  // get position/dimensions of element or viewport
  function getRectInView(element) {
    let rect = {};
    rect.left = 0;
    rect.top = 0;
    rect.right = document.documentElement.clientWidth;
    rect.bottom = document.documentElement.clientHeight;
    let style = {};

    if (element instanceof HTMLElement) {
      rect = element.getBoundingClientRect();
      style = window.getComputedStyle(element);
    }

    const margin = {};
    margin.left = parseFloat(style.marginLeftWidth) || 0;
    margin.top = parseFloat(style.marginTopWidth) || 0;
    margin.right = parseFloat(style.marginRightWidth) || 0;
    margin.bottom = parseFloat(style.marginBottomWidth) || 0;

    const border = {};
    border.left = parseFloat(style.borderLeftWidth) || 0;
    border.top = parseFloat(style.borderTopWidth) || 0;
    border.right = parseFloat(style.borderRightWidth) || 0;
    border.bottom = parseFloat(style.borderBottomWidth) || 0;

    const newRect = {};
    newRect.left = rect.left + margin.left + border.left;
    newRect.top = rect.top + margin.top + border.top;
    newRect.right = rect.right + margin.right + border.right;
    newRect.bottom = rect.bottom + margin.bottom + border.bottom;
    newRect.width = newRect.right - newRect.left;
    newRect.height = newRect.bottom - newRect.top;

    return newRect;
  }

  // get position of element relative to page
  function getRectInPage(element) {
    const rect = getRectInView(element);
    const body = getRectInView(document.body);

    const newRect = {};
    newRect.left = rect.left - body.left;
    newRect.top = rect.top - body.top;
    newRect.right = rect.right - body.left;
    newRect.bottom = rect.bottom - body.top;
    newRect.width = rect.width;
    newRect.height = rect.height;

    return newRect;
  }

  // get closest element before specified element that matches query
  function firstBefore(element, query) {
    while (element && element !== document.body && !element.matches(query))
      element = element.previousElementSibling || element.parentNode;

    return element;
  }

  // check if element is part of collapsed heading
  function isCollapsed(element) {
    while (element && element !== document.body) {
      if (element.dataset.collapsed === "true") return true;
      element = element.parentNode;
    }
    return false;
  }

  // expand any collapsed parent containers of element if necessary
  function expandElement(element) {
    if (isCollapsed(element)) {
      // accordion plugin
      const heading = firstBefore(element, "h2");
      if (heading) heading.click();
      // details/summary HTML element
      const summary = firstBefore(element, "summary");
      if (summary) summary.click();
    }
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);

    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // get list of elements after a start element up to element matching query
  function nextUntil(element, query, exclude) {
    const elements = [];
    while (((element = element.nextElementSibling), element)) {
      if (element.matches(query)) break;
      if (!element.matches(exclude)) elements.push(element);
    }
    return elements;
  }
</script>
<!--
  Accordion Plugin

  Allows sections of content under h2 headings to be collapsible.
-->

<script type="module">
  // whether to always start expanded ('false'), always start collapsed
  // ('true'), or start collapsed when screen small ('auto')
  const startCollapsed = "auto";

  // start script
  function start() {
    // run through each <h2> heading
    const headings = document.querySelectorAll("h2");
    for (const heading of headings) {
      addArrow(heading);

      // start expanded/collapsed based on option
      if (
        startCollapsed === "true" ||
        (startCollapsed === "auto" && isSmallScreen()) ||
        heading.dataset.collapsed === "true"
      )
        collapseHeading(heading);
      else expandElement(heading);
    }

    // attach hash change listener to window
    window.addEventListener("hashchange", onHashChange);
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) goToElement(target);
  }

  // add arrow to heading
  function addArrow(heading) {
    // add arrow button
    const arrow = document.createElement("button");
    arrow.innerHTML = document.querySelector(".icon_angle_down").innerHTML;
    arrow.classList.add("icon_button", "accordion_arrow");
    heading.insertBefore(arrow, heading.firstChild);

    // attach click listener to heading and button
    heading.addEventListener("click", onHeadingClick);
    arrow.addEventListener("click", onArrowClick);
  }

  // determine if on mobile-like device with small screen
  function isSmallScreen() {
    return Math.min(window.innerWidth, window.innerHeight) < 480;
  }

  // when <h2> heading is clicked
  function onHeadingClick(event) {
    // only collapse if <h2> itself is target of click (eg, user did
    // not click on anchor within <h2>)
    if (event.target === this) toggleCollapse(this);
  }

  // when arrow button is clicked
  function onArrowClick() {
    toggleCollapse(this.parentNode);
  }

  // collapse section if expanded, expand if collapsed
  function toggleCollapse(heading) {
    if (heading.dataset.collapsed === "false") collapseHeading(heading);
    else expandElement(heading);
  }

  // elements to exclude from collapse, such as table of contents panel,
  // hypothesis panel, etc
  const exclude = "#toc_panel, div.annotator-frame, #lightbox_overlay";

  // collapse section
  function collapseHeading(heading) {
    heading.setAttribute("data-collapsed", "true");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "true");
  }

  // expand section
  function expandElement(heading) {
    heading.setAttribute("data-collapsed", "false");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "false");
  }

  // get list of elements between this <h2> and next <h2> or <h1>
  // ("children" of the <h2> section)
  function getChildren(heading) {
    return nextUntil(heading, "h2, h1", exclude);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
  <!-- modified from: https://fontawesome.com/icons/angle-down -->
  <svg width="16" height="16" viewBox="0 0 448 512">
    <path
      fill="currentColor"
      d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* accordion arrow button */
    .accordion_arrow {
      margin-right: 10px;
    }

    /* arrow icon when <h2> data-collapsed attribute true */
    h2[data-collapsed="true"] > .accordion_arrow > svg {
      transform: rotate(-90deg);
    }

    /* all elements (except <h2>'s) when data-collapsed attribute true */
    *:not(h2)[data-collapsed="true"] {
      display: none;
    }

    /* accordion arrow button when hovered and <h2>'s when hovered */
    .accordion_arrow:hover,
    h2[data-collapsed="true"]:hover,
    h2[data-collapsed="false"]:hover {
      cursor: pointer;
    }
  }

  /* always hide accordion arrow button on print */
  @media only print {
    .accordion_arrow {
      display: none;
    }
  }
</style>
<!--
  Anchors Plugin

  Adds an anchor next to each of a certain type of element that provides a
  human-readable url to that specific item/position in the document (e.g.
  "manuscript.html#abstract"). It also makes it such that scrolling out of view
  of a target removes its identifier from the url.
-->

<script type="module">
  // which types of elements to add anchors next to, in "document.querySelector"
  // format
  const typesQuery =
    'h1, h2, h3, div[id^="fig:"], div[id^="tbl:"], span[id^="eq:"]';

  // start script
  function start() {
    // add anchor to each element of specified types
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) addAnchor(element);

    // attach scroll listener to window
    window.addEventListener("scroll", onScroll);
  }

  // when window is scrolled
  function onScroll() {
    // if url has hash and user has scrolled out of view of hash
    // target, remove hash from url
    const tolerance = 100;
    const target = getHashTarget();
    if (target) {
      if (
        target.getBoundingClientRect().top > window.innerHeight + tolerance ||
        target.getBoundingClientRect().bottom < 0 - tolerance
      )
        history.pushState(null, null, " ");
    }
  }

  // add anchor to element
  function addAnchor(element) {
    let addTo; // element to add anchor button to

    // if figure or table, modify withId and addTo to get expected
    // elements
    if (element.id.indexOf("fig:") === 0) {
      addTo = element.querySelector("figcaption");
    } else if (element.id.indexOf("tbl:") === 0) {
      addTo = element.querySelector("caption");
    } else if (element.id.indexOf("eq:") === 0) {
      addTo = element.querySelector(".eqnos-number");
    }

    addTo = addTo || element;
    const id = element.id || null;

    // do not add anchor if element doesn't have assigned id.
    // id is generated by pandoc and is assumed to be unique and
    // human-readable
    if (!id) return;

    // create anchor button
    const anchor = document.createElement("a");
    anchor.innerHTML = document.querySelector(".icon_link").innerHTML;
    anchor.title = "Link to this part of the document";
    anchor.classList.add("icon_button", "anchor");
    anchor.dataset.ignore = "true";
    anchor.href = "#" + id;
    addTo.appendChild(anchor);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- link icon -->

<template class="icon_link">
  <!-- modified from: https://fontawesome.com/icons/link -->
  <svg width="16" height="16" viewBox="0 0 512 512">
    <path
      fill="currentColor"
      d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* anchor button */
    .anchor {
      opacity: 0;
      margin-left: 5px;
    }

    /* anchor buttons within <h2>'s */
    h2 .anchor {
      margin-left: 10px;
    }

    /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
    *:hover > .anchor,
    .anchor:hover,
    .anchor:focus {
      opacity: 1;
    }

    /* anchor button when hovered */
    .anchor:hover {
      cursor: pointer;
    }
  }

  /* always show anchor button on devices with no mouse/hover ability */
  @media (hover: none) {
    .anchor {
      opacity: 1;
    }
  }

  /* always hide anchor button on print */
  @media only print {
    .anchor {
      display: none;
    }
  }
</style>
<!-- 
    Attributes Plugin

    Allows arbitrary HTML attributes to be attached to (almost) any element.
    Place an HTML comment inside or next to the desired element with the content:
    $attribute="value"
-->

<script type="module">
  // start script
  function start() {
    // get list of comments in document
    const comments = findComments();

    for (const comment of comments)
      if (comment.parentElement)
        addAttributes(comment.parentElement, comment.nodeValue.trim());
  }

  // add html attributes to specified element based on string of
  // html attributes and values
  function addAttributes(element, text) {
    // regex's for finding attribute/value pairs in the format of
    // attribute="value" or attribute='value
    const regex2 = /\$([a-zA-Z\-]+)?=\"(.+?)\"/;
    const regex1 = /\$([a-zA-Z\-]+)?=\'(.+?)\'/;

    // loop through attribute/value pairs
    let match;
    while ((match = text.match(regex2) || text.match(regex1))) {
      // get attribute and value from regex capture groups
      let attribute = match[1];
      let value = match[2];

      // remove from string
      text = text.substring(match.index + match[0].length);

      if (!attribute || !value) break;

      // set attribute of parent element
      try {
        element.setAttribute(attribute, value);
      } catch (error) {
        console.log(error);
      }

      // special case for colspan
      if (attribute === "colspan") removeTableCells(element, value);
    }
  }

  // get list of comment elements in document
  function findComments() {
    const comments = [];

    // iterate over comment nodes in document
    function acceptNode(node) {
      return NodeFilter.FILTER_ACCEPT;
    }
    const iterator = document.createNodeIterator(
      document.body,
      NodeFilter.SHOW_COMMENT,
      acceptNode
    );
    let node;
    while ((node = iterator.nextNode())) comments.push(node);

    return comments;
  }

  // remove certain number of cells after specified cell
  function removeTableCells(cell, number) {
    number = parseInt(number);
    if (!number) return;

    // remove elements
    for (; number > 1; number--) {
      if (cell.nextElementSibling) cell.nextElementSibling.remove();
    }
  }

  // start script on DOMContentLoaded instead of load to ensure this plugins
  // runs before other plugins
  window.addEventListener("DOMContentLoaded", start);
</script>
<!--
  Jump to First Plugin

  Adds a button next to each reference entry, figure, and table that jumps the
  page to the first occurrence of a link to that item in the manuscript.
-->

<script type="module">
  // whether to add buttons next to reference entries
  const references = "true";
  // whether to add buttons next to figures
  const figures = "true";
  // whether to add buttons next to tables
  const tables = "true";

  // start script
  function start() {
    if (references !== "false")
      makeButtons(`div[id^="ref-"]`, ".csl-left-margin", "reference");
    if (figures !== "false")
      makeButtons(`div[id^="fig:"]`, "figcaption", "figure");
    if (tables !== "false") makeButtons(`div[id^="tbl:"]`, "caption", "table");
  }

  // when jump button clicked
  function onButtonClick() {
    const first = getFirstOccurrence(this.dataset.id);
    if (!first) return;

    // update url hash so navigating "back" in history will return user to button
    window.location.hash = this.dataset.id;
    // scroll to link
    const timeout = function () {
      goToElement(first, window.innerHeight * 0.5);
    };
    window.setTimeout(timeout, 0);
  }

  // get first occurrence of link to item in document
  function getFirstOccurrence(id) {
    let query = "a";
    query += '[href="#' + id + '"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelector(query);
  }

  // add button next to each reference entry, figure, or table
  function makeButtons(query, containerQuery, subject) {
    const elements = document.querySelectorAll(query);
    for (const element of elements) {
      const id = element.id;
      const buttonContainer = element.querySelector(containerQuery);
      const first = getFirstOccurrence(id);

      // if can't find link to reference or place to put button, ignore
      if (!first || !buttonContainer) continue;

      // make jump button
      let button = document.createElement("button");
      button.classList.add("icon_button", "jump_arrow");
      button.title = `Jump to the first occurrence of this ${subject} in the document`;
      const icon = document.querySelector(".icon_angle_double_up");
      button.innerHTML = icon.innerHTML;
      button.dataset.id = id;
      button.dataset.ignore = "true";
      button.addEventListener("click", onButtonClick);
      buttonContainer.prepend(button);
    }
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
  <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
  <svg width="16" height="16" viewBox="0 0 320 512">
    <path
      fill="currentColor"
      d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* jump button */
    .jump_arrow {
      position: relative;
      top: 0.125em;
      margin-right: 5px;
    }
  }

  /* always hide jump button on print */
  @media only print {
    .jump_arrow {
      display: none;
    }
  }
</style>
<!-- 
    Lightbox Plugin

    Makes it such that when a user clicks on an image, the image fills the
    screen and the user can pan/drag/zoom the image and navigate between other
    images in the document.
-->

<script type="module">
  // list of possible zoom/scale factors
  const zooms =
    "0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8";
  // whether to fit image to view ('fit'), display at 100% and shrink if
  // necessary ('shrink'), or always display at 100% ('100')
  const defaultZoom = "fit";
  // whether to zoom in/out toward center of view ('true') or mouse ('false')
  const centerZoom = "false";

  // start script
  function start() {
    // run through each <img> element
    const imgs = document.querySelectorAll("figure > img");
    let count = 1;
    for (const img of imgs) {
      img.classList.add("lightbox_document_img");
      img.dataset.number = count;
      img.dataset.total = imgs.length;
      img.addEventListener("click", openLightbox);
      count++;
    }

    // attach mouse and key listeners to window
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("keyup", onKeyUp);
  }

  // when mouse is moved anywhere in window
  function onWindowMouseMove(event) {
    window.mouseX = event.clientX;
    window.mouseY = event.clientY;
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("lightbox_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("lightbox_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeLightbox();
        break;
    }
  }

  // open lightbox
  function openLightbox() {
    const lightbox = makeLightbox(this);
    if (!lightbox) return;

    blurBody(lightbox);
    document.body.appendChild(lightbox);
  }

  // make lightbox
  function makeLightbox(img) {
    // delete lightbox if it exists, start fresh
    closeLightbox();

    // create screen overlay containing lightbox
    const overlay = document.createElement("div");
    overlay.id = "lightbox_overlay";

    // create image info boxes
    const numberInfo = document.createElement("div");
    const zoomInfo = document.createElement("div");
    numberInfo.id = "lightbox_number_info";
    zoomInfo.id = "lightbox_zoom_info";

    // create container for image
    const imageContainer = document.createElement("div");
    imageContainer.id = "lightbox_image_container";
    const lightboxImg = makeLightboxImg(
      img,
      imageContainer,
      numberInfo,
      zoomInfo
    );
    imageContainer.appendChild(lightboxImg);

    // create bottom container for caption and navigation buttons
    const bottomContainer = document.createElement("div");
    bottomContainer.id = "lightbox_bottom_container";
    const caption = makeCaption(img);
    const prevButton = makePrevButton(img);
    const nextButton = makeNextButton(img);
    bottomContainer.appendChild(prevButton);
    bottomContainer.appendChild(caption);
    bottomContainer.appendChild(nextButton);

    // attach top middle and bottom to overlay
    overlay.appendChild(numberInfo);
    overlay.appendChild(zoomInfo);
    overlay.appendChild(imageContainer);
    overlay.appendChild(bottomContainer);

    return overlay;
  }

  // make <img> object that is intuitively draggable and zoomable
  function makeLightboxImg(sourceImg, container, numberInfoBox, zoomInfoBox) {
    // create copy of source <img>
    const img = sourceImg.cloneNode(true);
    img.classList.remove("lightbox_document_img");
    img.removeAttribute("id");
    img.removeAttribute("width");
    img.removeAttribute("height");
    img.style.position = "unset";
    img.style.margin = "0";
    img.style.padding = "0";
    img.style.width = "";
    img.style.height = "";
    img.style.minWidth = "";
    img.style.minHeight = "";
    img.style.maxWidth = "";
    img.style.maxHeight = "";
    img.id = "lightbox_img";

    // build sorted list of zoomSteps
    const zoomSteps = zooms.split(/[^0-9.]/).map((step) => parseFloat(step));
    zoomSteps.sort((a, b) => a - b);

    // <img> object property variables
    let zoom = 1;
    let translateX = 0;
    let translateY = 0;
    let clickMouseX = undefined;
    let clickMouseY = undefined;
    let clickTranslateX = undefined;
    let clickTranslateY = undefined;

    updateNumberInfo();

    // update image numbers displayed in info box
    function updateNumberInfo() {
      numberInfoBox.innerHTML =
        sourceImg.dataset.number + " of " + sourceImg.dataset.total;
    }

    // update zoom displayed in info box
    function updateZoomInfo() {
      let zoomInfo = zoom * 100;
      if (!Number.isInteger(zoomInfo)) zoomInfo = zoomInfo.toFixed(2);
      zoomInfoBox.innerHTML = zoomInfo + "%";
    }

    // move to closest zoom step above current zoom
    const zoomIn = function () {
      for (const zoomStep of zoomSteps) {
        if (zoomStep > zoom) {
          zoom = zoomStep;
          break;
        }
      }
      updateTransform();
    };

    // move to closest zoom step above current zoom
    const zoomOut = function () {
      zoomSteps.reverse();
      for (const zoomStep of zoomSteps) {
        if (zoomStep < zoom) {
          zoom = zoomStep;
          break;
        }
      }
      zoomSteps.reverse();

      updateTransform();
    };

    // update display of <img> based on scale/translate properties
    const updateTransform = function () {
      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      // get new width/height after scale
      const rect = img.getBoundingClientRect();
      // limit translate
      translateX = Math.max(translateX, -rect.width / 2);
      translateX = Math.min(translateX, rect.width / 2);
      translateY = Math.max(translateY, -rect.height / 2);
      translateY = Math.min(translateY, rect.height / 2);

      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      updateZoomInfo();
    };

    // fit <img> to container
    const fit = function () {
      // no x/y offset, 100% zoom by default
      translateX = 0;
      translateY = 0;
      zoom = 1;

      // widths of <img> and container
      const imgWidth = img.naturalWidth;
      const imgHeight = img.naturalHeight;
      const containerWidth = parseFloat(
        window.getComputedStyle(container).width
      );
      const containerHeight = parseFloat(
        window.getComputedStyle(container).height
      );

      // how much zooming is needed to fit <img> to container
      const xRatio = imgWidth / containerWidth;
      const yRatio = imgHeight / containerHeight;
      const maxRatio = Math.max(xRatio, yRatio);
      const newZoom = 1 / maxRatio;

      // fit <img> to container according to option
      if (defaultZoom === "shrink") {
        if (maxRatio > 1) zoom = newZoom;
      } else if (defaultZoom === "fit") zoom = newZoom;

      updateTransform();
    };

    // when mouse wheel is rolled anywhere in container
    const onContainerWheel = function (event) {
      if (!event) return;

      // let ctrl + mouse wheel to zoom behave as normal
      if (event.ctrlKey) return;

      // prevent normal scroll behavior
      event.preventDefault();
      event.stopPropagation();

      // point around which to scale img
      const viewRect = container.getBoundingClientRect();
      const viewX = (viewRect.left + viewRect.right) / 2;
      const viewY = (viewRect.top + viewRect.bottom) / 2;
      const originX = centerZoom === "true" ? viewX : mouseX;
      const originY = centerZoom === "true" ? viewY : mouseY;

      // get point on image under origin
      const oldRect = img.getBoundingClientRect();
      const oldPercentX = (originX - oldRect.left) / oldRect.width;
      const oldPercentY = (originY - oldRect.top) / oldRect.height;

      // increment/decrement zoom
      if (event.deltaY < 0) zoomIn();
      if (event.deltaY > 0) zoomOut();

      // get offset between previous image point and origin
      const newRect = img.getBoundingClientRect();
      const offsetX = originX - (newRect.left + newRect.width * oldPercentX);
      const offsetY = originY - (newRect.top + newRect.height * oldPercentY);

      // translate image to keep image point under origin
      translateX += offsetX;
      translateY += offsetY;

      // perform translate
      updateTransform();
    };

    // when container is clicked
    function onContainerClick(event) {
      // if container itself is target of click, and not other
      // element above it
      if (event.target === this) closeLightbox();
    }

    // when mouse button is pressed on image
    const onImageMouseDown = function (event) {
      // store original mouse position relative to image
      clickMouseX = window.mouseX;
      clickMouseY = window.mouseY;
      clickTranslateX = translateX;
      clickTranslateY = translateY;
      event.stopPropagation();
      event.preventDefault();
    };

    // when mouse button is released anywhere in window
    const onWindowMouseUp = function (event) {
      // reset original mouse position
      clickMouseX = undefined;
      clickMouseY = undefined;
      clickTranslateX = undefined;
      clickTranslateY = undefined;

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mouseup", onWindowMouseUp);
    };

    // when mouse is moved anywhere in window
    const onWindowMouseMove = function (event) {
      if (
        clickMouseX === undefined ||
        clickMouseY === undefined ||
        clickTranslateX === undefined ||
        clickTranslateY === undefined
      )
        return;

      // offset image based on original and current mouse position
      translateX = clickTranslateX + window.mouseX - clickMouseX;
      translateY = clickTranslateY + window.mouseY - clickMouseY;
      updateTransform();
      event.preventDefault();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mousemove", onWindowMouseMove);
    };

    // when window is resized
    const onWindowResize = function (event) {
      fit();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("resize", onWindowResize);
    };

    // attach the necessary event listeners
    img.addEventListener("dblclick", fit);
    img.addEventListener("mousedown", onImageMouseDown);
    container.addEventListener("wheel", onContainerWheel);
    container.addEventListener("mousedown", onContainerClick);
    container.addEventListener("touchstart", onContainerClick);
    window.addEventListener("mouseup", onWindowMouseUp);
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("resize", onWindowResize);

    // run fit() after lightbox atttached to document and <img> Loaded
    // so needed container and img dimensions available
    img.addEventListener("load", fit);

    return img;
  }

  // make caption
  function makeCaption(img) {
    const caption = document.createElement("div");
    caption.id = "lightbox_caption";
    const captionSource = img.nextElementSibling;
    if (captionSource.tagName.toLowerCase() === "figcaption") {
      const captionCopy = makeCopy(captionSource);
      caption.innerHTML = captionCopy.innerHTML;
    }

    caption.addEventListener("touchstart", function (event) {
      event.stopPropagation();
    });

    return caption;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // make button to jump to previous image in document
  function makePrevButton(img) {
    const prevButton = document.createElement("button");
    prevButton.id = "lightbox_prev_button";
    prevButton.title = "Jump to the previous image in the document [←]";
    prevButton.classList.add("icon_button", "lightbox_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;

    // attach click listeners to button
    prevButton.addEventListener("click", function () {
      getPrevImg(img).click();
    });

    return prevButton;
  }

  // make button to jump to next image in document
  function makeNextButton(img) {
    const nextButton = document.createElement("button");
    nextButton.id = "lightbox_next_button";
    nextButton.title = "Jump to the next image in the document [→]";
    nextButton.classList.add("icon_button", "lightbox_button");
    nextButton.innerHTML = document.querySelector(
      ".icon_caret_right"
    ).innerHTML;

    // attach click listeners to button
    nextButton.addEventListener("click", function () {
      getNextImg(img).click();
    });

    return nextButton;
  }

  // get previous image in document
  function getPrevImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if < 1
    if (index - 1 >= 0) index--;
    else index = imgs.length - 1;
    return imgs[index];
  }

  // get next image in document
  function getNextImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if > total
    if (index + 1 <= imgs.length - 1) index++;
    else index = 0;
    return imgs[index];
  }

  // close lightbox
  function closeLightbox() {
    focusBody();

    const lightbox = document.getElementById("lightbox_overlay");
    if (lightbox) lightbox.remove();
  }

  // make all elements behind lightbox non-focusable
  function blurBody(overlay) {
    const all = document.querySelectorAll("*");
    for (const element of all) element.tabIndex = -1;
    document.body.classList.add("body_no_scroll");
  }

  // make all elements focusable again
  function focusBody() {
    const all = document.querySelectorAll("*");
    for (const element of all) element.removeAttribute("tabIndex");
    document.body.classList.remove("body_no_scroll");
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* regular <img> in document when hovered */
    img.lightbox_document_img:hover {
      cursor: pointer;
    }

    .body_no_scroll {
      overflow: hidden !important;
    }

    /* screen overlay */
    #lightbox_overlay {
      display: flex;
      flex-direction: column;
      position: fixed;
      left: 0;
      top: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.75);
      z-index: 3;
    }

    /* middle area containing lightbox image */
    #lightbox_image_container {
      flex-grow: 1;
      display: flex;
      justify-content: center;
      align-items: center;
      overflow: hidden;
      position: relative;
      padding: 20px;
    }

    /* bottom area containing caption */
    #lightbox_bottom_container {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100px;
      min-height: 100px;
      max-height: 100px;
      background: rgba(0, 0, 0, 0.5);
    }

    /* image number info text box */
    #lightbox_number_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      left: 2px;
      top: 0;
      z-index: 4;
    }

    /* zoom info text box */
    #lightbox_zoom_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      right: 2px;
      top: 0;
      z-index: 4;
    }

    /* copy of image caption */
    #lightbox_caption {
      box-sizing: border-box;
      display: inline-block;
      width: 100%;
      max-height: 100%;
      padding: 10px 0;
      text-align: center;
      overflow-y: auto;
      color: #ffffff;
    }

    /* navigation previous/next button */
    .lightbox_button {
      width: 100px;
      height: 100%;
      min-width: 100px;
      min-height: 100%;
      color: #ffffff;
    }

    /* navigation previous/next button when hovered */
    .lightbox_button:hover {
      background: none !important;
    }

    /* navigation button icon */
    .lightbox_button > svg {
      height: 25px;
    }

    /* figure auto-number */
    #lightbox_caption > span:first-of-type {
      font-weight: bold;
      margin-right: 5px;
    }

    /* lightbox image when hovered */
    #lightbox_img:hover {
      cursor: grab;
    }

    /* lightbox image when grabbed */
    #lightbox_img:active {
      cursor: grabbing;
    }
  }

  /* when on screen < 480px wide */
  @media only screen and (max-width: 480px) {
    /* make navigation buttons skinnier on small screens to make more room for caption text */
    .lightbox_button {
      width: 50px;
      min-width: 50px;
    }
  }

  /* always hide lightbox on print */
  @media only print {
    #lightbox_overlay {
      display: none;
    }
  }
</style>
<!-- 
  Link Highlight Plugin

  Makes it such that when a user hovers or focuses a link, other links that have
  the same target will be highlighted. It also makes it such that when clicking
  a link, the target of the link (eg reference, figure, table) is briefly
  highlighted.
-->

<script type="module">
  // whether to also highlight links that go to external urls
  const externalLinks = "false";
  // whether user must click off to unhighlight instead of just
  // un-hovering
  const clickUnhighlight = "false";
  // whether to also highlight links that are unique
  const highlightUnique = "true";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach mouse and focus listeners to link
      link.addEventListener("mouseenter", onLinkFocus);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("mouseleave", onLinkUnhover);
    }

    // attach click and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("hashchange", onHashChange);

    // run hash change on window load in case user has navigated
    // directly to hash
    onHashChange();
  }

  // when link is focused (tabbed to) or hovered
  function onLinkFocus() {
    highlight(this);
  }

  // when link is unhovered
  function onLinkUnhover() {
    if (clickUnhighlight !== "true") unhighlightAll();
  }

  // when the mouse is clicked anywhere in window
  function onClick(event) {
    unhighlightAll();
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) glowElement(target);
  }

  // start glow sequence on an element
  function glowElement(element) {
    const startGlow = function () {
      onGlowEnd();
      element.dataset.glow = "true";
      element.addEventListener("animationend", onGlowEnd);
    };
    const onGlowEnd = function () {
      element.removeAttribute("data-glow");
      element.removeEventListener("animationend", onGlowEnd);
    };
    startGlow();
  }

  // highlight link and all others with same target
  function highlight(link) {
    // force unhighlight all to start fresh
    unhighlightAll();

    // get links with same target
    if (!link) return;
    const sameLinks = getSameLinks(link);

    // if link unique and option is off, exit and don't highlight
    if (sameLinks.length <= 1 && highlightUnique !== "true") return;

    // highlight all same links, and "select" (special highlight) this
    // one
    for (const sameLink of sameLinks) {
      if (sameLink === link) sameLink.setAttribute("data-selected", "true");
      else sameLink.setAttribute("data-highlighted", "true");
    }
  }

  // unhighlight all links
  function unhighlightAll() {
    const links = getLinks();
    for (const link of links) {
      link.setAttribute("data-selected", "false");
      link.setAttribute("data-highlighted", "false");
    }
  }

  // get links with same target
  function getSameLinks(link) {
    const results = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        results.push(otherLink);
    }
    return results;
  }

  // get all links of types we wish to handle
  function getLinks() {
    let query = "a";
    if (externalLinks !== "true") query += '[href^="#"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelectorAll(query);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<style>
  @media only screen {
    /* anything with data-highlighted attribute true */
    [data-highlighted="true"] {
      background: #ffeb3b;
    }

    /* anything with data-selected attribute true */
    [data-selected="true"] {
      background: #ff8a65 !important;
    }

    /* animation definition for glow */
    @keyframes highlight_glow {
      0% {
        background: none;
      }
      10% {
        background: #bbdefb;
      }
      100% {
        background: none;
      }
    }

    /* anything with data-glow attribute true */
    [data-glow="true"] {
      animation: highlight_glow 2s;
    }
  }
</style>
<!--
  Table of Contents Plugin

  Provides a "table of contents" (toc) panel on the side of the document that
  allows the user to conveniently navigate between sections of the document.
-->

<script type="module">
  // which types of elements to add links for, in "document.querySelector" format
  const typesQuery = "h1, h2, h3";
  // whether toc starts open. use 'true' or 'false', or 'auto' to
  // use 'true' behavior when screen wide enough and 'false' when not
  const startOpen = "false";
  // whether toc closes when clicking on toc link. use 'true' or
  // 'false', or 'auto' to use 'false' behavior when screen wide
  // enough and 'true' when not
  const clickClose = "auto";
  // if list item is more than this many characters, text will be
  // truncated
  const charLimit = "50";
  // whether or not to show bullets next to each toc item
  const bullets = "false";

  // start script
  function start() {
    // make toc panel and populate with entries (links to document
    // sections)
    const panel = makePanel();
    if (!panel) return;
    makeEntries(panel);
    // attach panel to document after making entries, so 'toc' heading
    // in panel isn't included in toc
    document.body.insertBefore(panel, document.body.firstChild);

    // initial panel state
    if (startOpen === "true" || (startOpen === "auto" && !isSmallScreen()))
      openPanel();
    else closePanel();

    // attach click, scroll, and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("scroll", onScroll);
    window.addEventListener("hashchange", onScroll);
    window.addEventListener("keyup", onKeyUp);
    onScroll();

    // add class to push document body down out of way of toc button
    document.body.classList.add("toc_body_nudge");
  }

  // determine if screen wide enough to fit toc panel
  function isSmallScreen() {
    // in default theme:
    // 816px = 8.5in = width of "page" (<body>) element
    // 260px = min width of toc panel (*2 for both sides of <body>)
    return window.innerWidth < 816 + 260 * 2;
  }

  // when mouse is clicked anywhere in window
  function onClick() {
    if (isSmallScreen()) closePanel();
  }

  // when window is scrolled or hash changed
  function onScroll() {
    highlightViewed();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    // close on esc
    if (event.key === "Escape") closePanel();
  }

  // find entry of currently viewed document section in toc and highlight
  function highlightViewed() {
    const firstId = getFirstInView(typesQuery);

    // get toc entries (links), unhighlight all, then highlight viewed
    const list = document.getElementById("toc_list");
    if (!firstId || !list) return;
    const links = list.querySelectorAll("a");
    for (const link of links) link.dataset.viewing = "false";
    const link = list.querySelector('a[href="#' + firstId + '"]');
    if (!link) return;
    link.dataset.viewing = "true";
  }

  // get first or previous toc listed element in top half of view
  function getFirstInView(query) {
    // get all elements matching query and with id
    const elements = document.querySelectorAll(query);
    const elementsWithIds = [];
    for (const element of elements) {
      if (element.id) elementsWithIds.push(element);
    }

    // get first or previous element in top half of view
    for (let i = 0; i < elementsWithIds.length; i++) {
      const element = elementsWithIds[i];
      const prevElement = elementsWithIds[Math.max(0, i - 1)];
      if (element.getBoundingClientRect().top >= 0) {
        if (element.getBoundingClientRect().top < window.innerHeight / 2)
          return element.id;
        else return prevElement.id;
      }
    }
  }

  // make panel
  function makePanel() {
    // create panel
    const panel = document.createElement("div");
    panel.id = "toc_panel";
    if (bullets === "true") panel.dataset.bullets = "true";

    // create header
    const header = document.createElement("div");
    header.id = "toc_header";

    // create toc button
    const button = document.createElement("button");
    button.id = "toc_button";
    button.innerHTML = document.querySelector(".icon_th_list").innerHTML;
    button.title = "Table of Contents";
    button.classList.add("icon_button");

    // create header text
    const text = document.createElement("h4");
    text.innerHTML = "Table of Contents";

    // create container for toc list
    const list = document.createElement("div");
    list.id = "toc_list";

    // attach click listeners
    panel.addEventListener("click", onPanelClick);
    header.addEventListener("click", onHeaderClick);
    button.addEventListener("click", onButtonClick);

    // attach elements
    header.appendChild(button);
    header.appendChild(text);
    panel.appendChild(header);
    panel.appendChild(list);

    return panel;
  }

  // create toc entries (links) to each element of the specified types
  function makeEntries(panel) {
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) {
      // do not add link if element doesn't have assigned id
      if (!element.id) continue;

      // create link/list item
      const link = document.createElement("a");
      link.classList.add("toc_link");
      switch (element.tagName.toLowerCase()) {
        case "h1":
          link.dataset.level = "1";
          break;
        case "h2":
          link.dataset.level = "2";
          break;
        case "h3":
          link.dataset.level = "3";
          break;
        case "h4":
          link.dataset.level = "4";
          break;
      }
      link.title = element.innerText;
      let text = element.innerText;
      if (text.length > charLimit) text = text.slice(0, charLimit) + "...";
      link.innerHTML = text;
      link.href = "#" + element.id;
      link.addEventListener("click", onLinkClick);

      // attach link
      panel.querySelector("#toc_list").appendChild(link);
    }
  }

  // when panel is clicked
  function onPanelClick(event) {
    // stop click from propagating to window/document and closing panel
    event.stopPropagation();
  }

  // when header itself is clicked
  function onHeaderClick(event) {
    togglePanel();
  }

  // when button is clicked
  function onButtonClick(event) {
    togglePanel();
    // stop header underneath button from also being clicked
    event.stopPropagation();
  }

  // when link is clicked
  function onLinkClick(event) {
    if (clickClose === "true" || (clickClose === "auto" && isSmallScreen()))
      closePanel();
    else openPanel();
  }

  // open panel if closed, close if opened
  function togglePanel() {
    const panel = document.getElementById("toc_panel");
    if (!panel) return;

    if (panel.dataset.open === "true") closePanel();
    else openPanel();
  }

  // open panel
  function openPanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "true";
  }

  // close panel
  function closePanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "false";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- th list icon -->

<template class="icon_th_list">
  <!-- modified from: https://fontawesome.com/icons/th-list -->
  <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
    <path
      fill="currentColor"
      d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* toc panel */
    #toc_panel {
      box-sizing: border-box;
      position: fixed;
      top: 0;
      left: 0;
      background: #ffffff;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      z-index: 2;
    }

    /* toc panel when closed */
    #toc_panel[data-open="false"] {
      min-width: 60px;
      width: 60px;
      height: 60px;
      border-right: solid 1px #bdbdbd;
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc panel when open */
    #toc_panel[data-open="true"] {
      min-width: 260px;
      max-width: 480px;
      /* keep panel edge consistent distance away from "page" edge */
      width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
      bottom: 0;
      border-right: solid 1px #bdbdbd;
    }

    /* toc panel header */
    #toc_header {
      box-sizing: border-box;
      display: flex;
      flex-direction: row;
      align-items: center;
      height: 60px;
      margin: 0;
      padding: 20px;
    }

    /* toc panel header when hovered */
    #toc_header:hover {
      cursor: pointer;
    }

    /* toc panel header when panel open */
    #toc_panel[data-open="true"] > #toc_header {
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc open/close header button */
    #toc_button {
      margin-right: 20px;
    }

    /* hide toc list and header text when closed */
    #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
    #toc_panel[data-open="false"] > #toc_list {
      display: none;
    }

    /* toc list of entries */
    #toc_list {
      box-sizing: border-box;
      width: 100%;
      padding: 20px;
      position: absolute;
      top: calc(60px + 1px);
      bottom: 0;
      overflow: auto;
    }

    /* toc entry, link to section in document */
    .toc_link {
      display: block;
      padding: 5px;
      position: relative;
      font-weight: 600;
      text-decoration: none;
    }

    /* toc entry when hovered or when "viewed" */
    .toc_link:hover,
    .toc_link[data-viewing="true"] {
      background: #f5f5f5;
    }

    /* toc entry, level 1 indentation */
    .toc_link[data-level="1"] {
      margin-left: 0;
    }

    /* toc entry, level 2 indentation */
    .toc_link[data-level="2"] {
      margin-left: 20px;
    }

    /* toc entry, level 3 indentation */
    .toc_link[data-level="3"] {
      margin-left: 40px;
    }

    /* toc entry, level 4 indentation */
    .toc_link[data-level="4"] {
      margin-left: 60px;
    }

    /* toc entry bullets */
    #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
      position: absolute;
      left: -15px;
      top: -1px;
      font-size: 1.5em;
    }

    /* toc entry, level 2 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
      content: "\2022";
    }

    /* toc entry, level 3 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
      content: "\25AB";
    }

    /* toc entry, level 4 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
      content: "-";
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* push <body> ("page") element down to make room for toc icon */
    .toc_body_nudge {
      padding-top: 60px;
    }

    /* toc icon when panel closed and not hovered */
    #toc_panel[data-open="false"]:not(:hover) {
      background: rgba(255, 255, 255, 0.75);
    }
  }

  /* always hide toc panel on print */
  @media only print {
    #toc_panel {
      display: none;
    }
  }
</style>
<!-- 
  Tooltips Plugin

  Makes it such that when the user hovers or focuses a link to a citation or
  figure, a tooltip appears with a preview of the reference content, along with
  arrows to navigate between instances of the same reference in the document.
-->

<script type="module">
  // whether user must click off to close tooltip instead of just un-hovering
  const clickClose = "false";
  // delay (in ms) between opening and closing tooltip
  const delay = "100";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach hover and focus listeners to link
      link.addEventListener("mouseover", onLinkHover);
      link.addEventListener("mouseleave", onLinkUnhover);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("touchend", onLinkTouch);
    }

    // attach mouse, key, and resize listeners to window
    window.addEventListener("mousedown", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("keyup", onKeyUp);
    window.addEventListener("resize", onResize);
  }

  // when link is hovered
  function onLinkHover() {
    // function to open tooltip
    const delayOpenTooltip = function () {
      openTooltip(this);
    }.bind(this);

    // run open function after delay
    this.openTooltipTimer = window.setTimeout(delayOpenTooltip, delay);
  }

  // when mouse leaves link
  function onLinkUnhover() {
    // cancel opening tooltip
    window.clearTimeout(this.openTooltipTimer);

    // don't close on unhover if option specifies
    if (clickClose === "true") return;

    // function to close tooltip
    const delayCloseTooltip = function () {
      // if tooltip open and if mouse isn't over tooltip, close
      const tooltip = document.getElementById("tooltip");
      if (tooltip && !tooltip.matches(":hover")) closeTooltip();
    };

    // run close function after delay
    this.closeTooltipTimer = window.setTimeout(delayCloseTooltip, delay);
  }

  // when link is focused (tabbed to)
  function onLinkFocus(event) {
    openTooltip(this);
  }

  // when link is touched on touch screen
  function onLinkTouch(event) {
    // attempt to force hover state on first tap always, and trigger
    // regular link click (and navigation) on second tap
    if (event.target === document.activeElement) event.target.click();
    else {
      document.activeElement.blur();
      event.target.focus();
    }
    if (event.cancelable) event.preventDefault();
    event.stopPropagation();
    return false;
  }

  // when mouse is clicked anywhere in window
  function onClick(event) {
    closeTooltip();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("tooltip_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("tooltip_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeTooltip();
        break;
    }
  }

  // when window is resized or zoomed
  function onResize() {
    closeTooltip();
  }

  // get all links of types we wish to handle
  function getLinks() {
    const queries = [];
    // exclude buttons, anchor links, toc links, etc
    const exclude =
      ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    queries.push('a[href^="#ref-"]' + exclude); // citation links
    queries.push('a[href^="#fig:"]' + exclude); // figure links
    const query = queries.join(", ");
    return document.querySelectorAll(query);
  }

  // get links with same target, get index of link in set, get total
  // same links
  function getSameLinks(link) {
    const sameLinks = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        sameLinks.push(otherLink);
    }

    return {
      elements: sameLinks,
      index: sameLinks.indexOf(link),
      total: sameLinks.length,
    };
  }

  // open tooltip
  function openTooltip(link) {
    // delete tooltip if it exists, start fresh
    closeTooltip();

    // make tooltip element
    const tooltip = makeTooltip(link);

    // if source couldn't be found and tooltip not made, exit
    if (!tooltip) return;

    // make navbar elements
    const navBar = makeNavBar(link);
    if (navBar) tooltip.firstElementChild.appendChild(navBar);

    // attach tooltip to page
    document.body.appendChild(tooltip);

    // position tooltip
    const position = function () {
      positionTooltip(link);
    };
    position();

    // if tooltip contains images, position again after they've loaded
    const imgs = tooltip.querySelectorAll("img");
    for (const img of imgs) img.addEventListener("load", position);
  }

  // close (delete) tooltip
  function closeTooltip() {
    const tooltip = document.getElementById("tooltip");
    if (tooltip) tooltip.remove();
  }

  // make tooltip
  function makeTooltip(link) {
    // get target element that link points to
    const source = getSource(link);

    // if source can't be found, exit
    if (!source) return;

    // create new tooltip
    const tooltip = document.createElement("div");
    tooltip.id = "tooltip";
    const tooltipContent = document.createElement("div");
    tooltipContent.id = "tooltip_content";
    tooltip.appendChild(tooltipContent);

    // make copy of source node and put in tooltip
    const sourceCopy = makeCopy(source);
    tooltipContent.appendChild(sourceCopy);

    // attach mouse event listeners
    tooltip.addEventListener("click", onTooltipClick);
    tooltip.addEventListener("mousedown", onTooltipClick);
    tooltip.addEventListener("touchstart", onTooltipClick);
    tooltip.addEventListener("mouseleave", onTooltipUnhover);

    // (for interaction with lightbox plugin)
    // transfer click on tooltip copied img to original img
    const sourceImg = source.querySelector("img");
    const sourceCopyImg = sourceCopy.querySelector("img");
    if (sourceImg && sourceCopyImg) {
      const clickImg = function () {
        sourceImg.click();
        closeTooltip();
      };
      sourceCopyImg.addEventListener("click", clickImg);
    }

    return tooltip;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
      "class",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // when tooltip is clicked
  function onTooltipClick(event) {
    // when user clicks on tooltip, stop click from transferring
    // outside of tooltip (eg, click off to close tooltip, or eg click
    // off to unhighlight same refs)
    event.stopPropagation();
  }

  // when tooltip is unhovered
  function onTooltipUnhover(event) {
    if (clickClose === "true") return;

    // make sure new mouse/touch/focus no longer over tooltip or any
    // element within it
    const tooltip = document.getElementById("tooltip");
    if (!tooltip) return;
    if (this.contains(event.relatedTarget)) return;

    closeTooltip();
  }

  // make nav bar to go betwen prev/next instances of same reference
  function makeNavBar(link) {
    // find other links to the same source
    const sameLinks = getSameLinks(link);

    // don't show nav bar when singular reference
    if (sameLinks.total <= 1) return;

    // find prev/next links with same target
    const prevLink = getPrevLink(link, sameLinks);
    const nextLink = getNextLink(link, sameLinks);

    // create nav bar
    const navBar = document.createElement("div");
    navBar.id = "tooltip_nav_bar";
    const text = sameLinks.index + 1 + " of " + sameLinks.total;

    // create nav bar prev/next buttons
    const prevButton = document.createElement("button");
    const nextButton = document.createElement("button");
    prevButton.id = "tooltip_prev_button";
    nextButton.id = "tooltip_next_button";
    prevButton.title =
      "Jump to the previous occurence of this item in the document [←]";
    nextButton.title =
      "Jump to the next occurence of this item in the document [→]";
    prevButton.classList.add("icon_button");
    nextButton.classList.add("icon_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;
    nextButton.innerHTML =
      document.querySelector(".icon_caret_right").innerHTML;
    navBar.appendChild(prevButton);
    navBar.appendChild(document.createTextNode(text));
    navBar.appendChild(nextButton);

    // attach click listeners to buttons
    prevButton.addEventListener("click", function () {
      onPrevNextClick(link, prevLink);
    });
    nextButton.addEventListener("click", function () {
      onPrevNextClick(link, nextLink);
    });

    return navBar;
  }

  // get previous link with same target
  function getPrevLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if < 1
    let index;
    if (sameLinks.index - 1 >= 0) index = sameLinks.index - 1;
    else index = sameLinks.total - 1;
    return sameLinks.elements[index];
  }

  // get next link with same target
  function getNextLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if > total
    let index;
    if (sameLinks.index + 1 <= sameLinks.total - 1) index = sameLinks.index + 1;
    else index = 0;
    return sameLinks.elements[index];
  }

  // get element that is target of link or url hash
  function getSource(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector('[id="' + id + '"]');
    if (!target) return;

    // if ref or figure, modify target to get expected element
    if (id.indexOf("ref-") === 0) target = target.querySelector(":nth-child(2)");
    else if (id.indexOf("fig:") === 0) target = target.querySelector("figure");

    return target;
  }

  // when prev/next arrow button is clicked
  function onPrevNextClick(link, prevNextLink) {
    if (link && prevNextLink)
      goToElement(prevNextLink, window.innerHeight * 0.5);
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);
    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // determine position to place tooltip based on link position in
  // viewport and tooltip size
  function positionTooltip(link, left, top) {
    const tooltipElement = document.getElementById("tooltip");
    if (!tooltipElement) return;

    // get convenient vars for position/dimensions of
    // link/tooltip/page/view
    link = getRectInPage(link);
    const tooltip = getRectInPage(tooltipElement);
    const view = getRectInPage();

    // horizontal positioning
    if (left)
      // use explicit value
      left = left;
    else if (link.left + tooltip.width < view.right)
      // fit tooltip to right of link
      left = link.left;
    else if (link.right - tooltip.width > view.left)
      // fit tooltip to left of link
      left = link.right - tooltip.width;
    // center tooltip in view
    else left = (view.right - view.left) / 2 - tooltip.width / 2;

    // vertical positioning
    if (top)
      // use explicit value
      top = top;
    else if (link.top - tooltip.height > view.top)
      // fit tooltip above link
      top = link.top - tooltip.height;
    else if (link.bottom + tooltip.height < view.bottom)
      // fit tooltip below link
      top = link.bottom;
    else {
      // center tooltip in view
      top = view.top + view.height / 2 - tooltip.height / 2;
      // nudge off of link to left/right if possible
      if (link.right + tooltip.width < view.right) left = link.right;
      else if (link.left - tooltip.width > view.left)
        left = link.left - tooltip.width;
    }

    tooltipElement.style.left = left + "px";
    tooltipElement.style.top = top + "px";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* tooltip container */
    #tooltip {
      position: absolute;
      width: 50%;
      min-width: 240px;
      max-width: 75%;
      z-index: 1;
    }

    /* tooltip content */
    #tooltip_content {
      margin-bottom: 5px;
      padding: 20px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
      overflow-wrap: break-word;
    }

    /* tooltip copy of paragraphs and figures */
    #tooltip_content > p,
    #tooltip_content > figure {
      margin: 0;
      max-height: 320px;
      overflow-y: auto;
    }

    /* tooltip copy of <img> */
    #tooltip_content > figure > img,
    #tooltip_content > figure > svg {
      max-height: 260px;
    }

    /* navigation bar */
    #tooltip_nav_bar {
      margin-top: 10px;
      text-align: center;
    }

    /* navigation bar previous/next buton */
    #tooltip_nav_bar > .icon_button {
      position: relative;
      top: 3px;
    }

    /* navigation bar previous button */
    #tooltip_nav_bar > .icon_button:first-of-type {
      margin-right: 5px;
    }

    /* navigation bar next button */
    #tooltip_nav_bar > .icon_button:last-of-type {
      margin-left: 5px;
    }
  }

  /* always hide tooltip on print */
  @media only print {
    #tooltip {
      display: none;
    }
  }
</style>
<!--
  Analytics Plugin (third-party) 
  
  Copy and paste code from Google Analytics or similar service here.
-->
<!-- 
  Annotations Plugin

  Allows public annotation of the  manuscript. See https://web.hypothes.is/.
-->

<script type="module">
  // configuration
  window.hypothesisConfig = function () {
    return {
      branding: {
        accentColor: "#2196f3",
        appBackgroundColor: "#f8f8f8",
        ctaBackgroundColor: "#f8f8f8",
        ctaTextColor: "#000000",
        selectionFontFamily: "Open Sans, Helvetica, sans serif",
        annotationFontFamily: "Open Sans, Helvetica, sans serif",
      },
    };
  };

  // hypothesis client script
  const embed = "https://hypothes.is/embed.js";
  // hypothesis annotation count query url
  const query = "https://api.hypothes.is/api/search?limit=0&url=";

  // start script
  function start() {
    const button = makeButton();
    document.body.insertBefore(button, document.body.firstChild);
    insertCount(button);
  }

  // make button
  function makeButton() {
    // create button
    const button = document.createElement("button");
    button.id = "hypothesis_button";
    button.innerHTML = document.querySelector(".icon_hypothesis").innerHTML;
    button.title = "Hypothesis annotations";
    button.classList.add("icon_button");

    function onClick(event) {
      onButtonClick(event, button);
    }

    // attach click listeners
    button.addEventListener("click", onClick);

    return button;
  }

  // insert annotations count
  async function insertCount(button) {
    // get annotation count from Hypothesis based on url
    let count = "-";
    try {
      const canonical = document.querySelector('link[rel="canonical"]');
      const location = window.location;
      const url = encodeURIComponent((canonical || location).href);
      const response = await fetch(query + url);
      const json = await response.json();
      count = json.total || "-";
    } catch (error) {
      console.log(error);
    }

    // put count into button
    const counter = document.createElement("span");
    counter.id = "hypothesis_count";
    counter.innerHTML = count;
    button.title = "View " + count + " Hypothesis annotations";
    button.append(counter);
  }

  // when button is clicked
  function onButtonClick(event, button) {
    const script = document.createElement("script");
    script.src = embed;
    document.body.append(script);
    button.remove();
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- hypothesis icon -->

<template class="icon_hypothesis">
  <!-- modified from: https://simpleicons.org/icons/hypothesis.svg / https://git.io/Jf1VB -->
  <svg width="16" height="16" viewBox="0 0 24 24" tabindex="-1">
    <path
      fill="currentColor"
      d="M3.43 0C2.5 0 1.72 .768 1.72 1.72V18.86C1.72 19.8 2.5 20.57 3.43 20.57H9.38L12 24L14.62 20.57H20.57C21.5 20.57 22.29 19.8 22.29 18.86V1.72C22.29 .77 21.5 0 20.57 0H3.43M5.14 3.43H7.72V9.43S8.58 7.72 10.28 7.72C12 7.72 13.74 8.57 13.74 11.24V17.14H11.16V12C11.16 10.61 10.28 10.07 9.43 10.29C8.57 10.5 7.72 11.41 7.72 13.29V17.14H5.14V3.43M18 13.72C18.95 13.72 19.72 14.5 19.72 15.42A1.71 1.71 0 0 1 18 17.13A1.71 1.71 0 0 1 16.29 15.42C16.29 14.5 17.05 13.71 18 13.71Z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  /* hypothesis activation button */
  #hypothesis_button {
    box-sizing: border-box;
    position: fixed;
    top: 0;
    right: 0;
    width: 60px;
    height: 60px;
    background: #ffffff;
    border-radius: 0;
    border-left: solid 1px #bdbdbd;
    border-bottom: solid 1px #bdbdbd;
    box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
    z-index: 2;
  }

  /* hypothesis button svg */
  #hypothesis_button > svg {
    position: relative;
    top: -4px;
  }

  /* hypothesis annotation count */
  #hypothesis_count {
    position: absolute;
    left: 0;
    right: 0;
    bottom: 5px;
  }

  /* side panel */
  .annotator-frame {
    width: 280px !important;
  }

  /* match highlight color to rest of theme */
  .annotator-highlights-always-on .annotator-hl {
    background-color: #ffeb3b !important;
  }

  /* match focused color to rest of theme */
  .annotator-hl.annotator-hl-focused {
    background-color: #ff8a65 !important;
  }

  /* match bucket bar color to rest of theme */
  .annotator-bucket-bar {
    background: #f5f5f5 !important;
  }

  /* always hide button, toolbar, and tooltip on print */
  @media only print {
    #hypothesis_button {
      display: none;
    }

    .annotator-frame {
      display: none !important;
    }

    hypothesis-adder {
      display: none !important;
    }
  }
</style>
<!-- 
  Mathjax Plugin (third-party) 

  Allows the proper rendering of math/equations written in LaTeX.
  See https://www.mathjax.org/.
-->

<script type="text/x-mathjax-config">
  // configuration
  MathJax.Hub.Config({
    "CommonHTML": { linebreaks: { automatic: true } },
    "HTML-CSS": { linebreaks: { automatic: true } },
    "SVG": { linebreaks: { automatic: true } },
    "fast-preview": { disabled: true }
  });
</script>

<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A=="
  crossorigin="anonymous"
></script>

<style>
  /* mathjax containers */
  .math.display > span:not(.MathJax_Preview) {
    /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
    display: flex !important;
    overflow-x: auto !important;
    overflow-y: hidden !important;
    justify-content: center;
    align-items: center;
    margin: 0 !important;
  }

  /* right click menu */
  .MathJax_Menu {
    border-radius: 5px !important;
    border: solid 1px #bdbdbd !important;
    box-shadow: none !important;
  }

  /* equation auto-number */
  span[id^="eq:"] > span.math.display + span {
    font-weight: 600;
  }

  /* equation */
  span[id^="eq:"] > span.math.display > span {
    /* nudge to make room for equation auto-number and anchor */
    margin-right: 60px !important;
  }
</style>
</body>
</html>
